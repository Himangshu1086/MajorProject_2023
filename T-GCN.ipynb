{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install tf_gnn\n",
    "#pip install spektral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorly as tl\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, GRU, Reshape, Concatenate, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route = pd.read_excel('route_data/U101.xlsx',index_col=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION HOURLY PATTERN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def scale_data(arr):\n",
    "    # Reshape the array to a 2D matrix with shape (m*n, p)\n",
    "    reshaped_arr = arr.reshape((-1, arr.shape[-1]))\n",
    "    # Create a MinMaxScaler object and apply it to the reshaped array\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_arr = scaler.fit_transform(reshaped_arr)\n",
    "    # Reshape the scaled array back to the original shape\n",
    "    scaled_arr = scaled_arr.reshape(arr.shape)\n",
    "    return scaled_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare(df_route):\n",
    "    df_route = df_route[['ETD_DATE','Hour','ORIGIN','DESTINATION']]\n",
    "    df_route_unique = pd.DataFrame(df_route.value_counts())\n",
    "    df_route_unique = df_route_unique.reset_index()\n",
    "    df_route_unique.rename(columns={0:'TRAFFIC FLOW'},inplace=True)\n",
    "    land_use = pd.read_csv(\"Land_Use.csv\")\n",
    "    land_use.fillna(0,inplace=True)\n",
    "    # merged_data_final = pd.merge(df_route_unique, land_use, left_on='ORIGIN', right_on='STOPS')\n",
    "    # merged_data_final.drop(columns=['STOPS'],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    ten_graph_data = []\n",
    "    grp_hr = df_route_unique.groupby(['ETD_DATE','Hour'])\n",
    "    for i, df in grp_hr:\n",
    "        adj_matrix = np.zeros((51,51))\n",
    "        for index, row in df.iterrows():\n",
    "            adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] = adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] + int(row['TRAFFIC FLOW'])\n",
    "        ten_graph_data.append(tl.tensor(adj_matrix).reshape(51,51))\n",
    "    tensor_graph_data = tf.convert_to_tensor(ten_graph_data)\n",
    "    tensor_graph_data = np.array(tensor_graph_data)\n",
    "\n",
    "\n",
    "    unique_values = pd.unique(df_route_unique[['ORIGIN','DESTINATION']].values.ravel('K'))\n",
    "    land_use[land_use['STOPS'].isin(unique_values)==False][['COMMERCIAL','PUBLIC_and_SEMI_PUBLIC','INDUSTRIAL','RESIDENTIAL','PARKS','PUBLIC_UTILITIES']] = 0\n",
    "\n",
    "    pivot_table_for_node_features = np.array(land_use[['COMMERCIAL', 'PUBLIC_and_SEMI_PUBLIC', 'INDUSTRIAL', 'RESIDENTIAL','PARKS', 'PUBLIC_UTILITIES']])\n",
    "    list_node_features = []\n",
    "    for i in range(len(tensor_graph_data)):\n",
    "            list_node_features.append(pivot_table_for_node_features)\n",
    "    tensor_node_feature = tf.convert_to_tensor(list_node_features)\n",
    "    tensor_node_feature = np.array(tensor_node_feature)\n",
    "\n",
    "\n",
    "\n",
    "    ten_target_value = []\n",
    "    grp_date = df_route_unique.groupby(['ETD_DATE','Hour'])\n",
    "    for i, df in grp_date:\n",
    "        adj_matrix_target = np.zeros((51))\n",
    "        for index, row in df.iterrows():\n",
    "            adj_matrix_target[int(row['ORIGIN'])] = adj_matrix_target[int(row['ORIGIN'])] + int(row['TRAFFIC FLOW'])\n",
    "        ten_target_value.append(tl.tensor(adj_matrix_target))\n",
    "    tensor_target_value = tf.convert_to_tensor(ten_target_value)\n",
    "    tensor_target_value = np.array(tensor_target_value).reshape(len(tensor_graph_data),51,1)\n",
    "\n",
    "    tensor_node_feature = scale_data(tensor_node_feature)\n",
    "    tensor_graph_data = scale_data(tensor_graph_data)\n",
    "\n",
    "\n",
    "    return tensor_graph_data,tensor_node_feature,tensor_target_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_route = df_route[['ETD_DATE','ORIGIN','DESTINATION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_route_unique = pd.DataFrame(df_route.value_counts())\n",
    "# df_route_unique = df_route_unique.reset_index()\n",
    "# df_route_unique.rename(columns={0:'TRAFFIC FLOW'},inplace=True)\n",
    "# land_use = pd.read_csv(\"Land_Use.csv\")\n",
    "# land_use.fillna(0,inplace=True)\n",
    "# merged_data_final = pd.merge(df_route_unique, land_use, left_on='ORIGIN', right_on='STOPS')\n",
    "# merged_data_final.drop(columns=['STOPS'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data_final.sort_values(by='ETD_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique values of the origin and destination columns\n",
    "# unique_values = pd.unique(merged_data_final[['ORIGIN','DESTINATION']].values.ravel('K'))\n",
    "\n",
    "# # Create a dictionary to map each unique value to a corresponding integer\n",
    "# mapping_dict = {value: index for index, value in enumerate(unique_values)}\n",
    "\n",
    "# # Use the `map` method to replace the origin and destination values with the mapped integer values\n",
    "# merged_data_final['ORIGIN'] = merged_data_final['ORIGIN'].map(mapping_dict)\n",
    "# merged_data_final['DESTINATION'] = merged_data_final['DESTINATION'].map(mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ten_graph_data = []\n",
    "# grp_hr = merged_data_final.groupby(['Hour'])\n",
    "# for i, df in grp_hr:\n",
    "#     adj_matrix = np.zeros((17,17))\n",
    "#     for index, row in df.iterrows():\n",
    "#         adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] = 1\n",
    "#     ten_graph_data.append(tl.tensor(adj_matrix).reshape(17,17))\n",
    "# tensor_graph_data = tf.convert_to_tensor(ten_graph_data)\n",
    "# # tensor_graph_data = tf.transpose(tensor_graph_data, perm=[1, 2, 0])\n",
    "# tensor_graph_data = np.array(tensor_graph_data)\n",
    "# tensor_graph_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ten_graph_data = []\n",
    "# grp_hr = merged_data_final.groupby(['ETD_DATE'])\n",
    "# for i, df in grp_hr:\n",
    "#     adj_matrix = np.zeros((51,51))\n",
    "#     for index, row in df.iterrows():\n",
    "#             adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] = adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] + int(row['TRAFFIC FLOW'])\n",
    "#     ten_graph_data.append(tl.tensor(adj_matrix).reshape(51,51))\n",
    "# tensor_graph_data = tf.convert_to_tensor(ten_graph_data)\n",
    "# # tensor_graph_data = tf.transpose(tensor_graph_data, perm=[1, 2, 0])\n",
    "# tensor_graph_data = np.array(tensor_graph_data)\n",
    "# tensor_graph_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node features represent information about each node in the graph at each time stamp.Tensor of shape [N,D,F] where F is number of features per node.\n",
    "# pivot_table_for_node_features = merged_data_final.pivot_table(index='ORIGIN',columns='Hour',values=merged_data_final[['COMMERCIAL', 'PUBLIC_and_SEMI_PUBLIC', 'INDUSTRIAL', 'RESIDENTIAL',\n",
    "#        'PARKS', 'PUBLIC_UTILITIES']]).fillna(0)\n",
    "# list_node_features = []\n",
    "# pv_nf = tl.tensor(pivot_table_for_node_features)\n",
    "# for i in range(17):\n",
    "#         list_node_features.append(tl.tensor(pivot_table_for_node_features)[i].reshape(-1,6))\n",
    "# tensor_node_feature = tf.convert_to_tensor(list_node_features)\n",
    "# tensor_node_feature = tf.transpose(tensor_node_feature, perm=[1, 0, 2])\n",
    "# tensor_node_feature = np.array(tensor_node_feature)\n",
    "# tensor_node_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_values = pd.unique(merged_data_final[['ORIGIN','DESTINATION']].values.ravel('K'))\n",
    "# land_use[land_use['STOPS'].isin(unique_values)==False][['COMMERCIAL','PUBLIC_and_SEMI_PUBLIC','INDUSTRIAL','RESIDENTIAL','PARKS','PUBLIC_UTILITIES']] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node features represent information about each node in the graph at each time stamp.Tensor of shape [N,D,F] where F is number of features per node.\n",
    "# bus_stops_land_use = land_use[land_use['STOPS'].isin(unique_values)]\n",
    "# pivot_table_for_node_features = np.array(land_use[['COMMERCIAL', 'PUBLIC_and_SEMI_PUBLIC', 'INDUSTRIAL', 'RESIDENTIAL','PARKS', 'PUBLIC_UTILITIES']])\n",
    "# list_node_features = []\n",
    "# for i in range(183):\n",
    "#         list_node_features.append(pivot_table_for_node_features)\n",
    "# tensor_node_feature = tf.convert_to_tensor(list_node_features)\n",
    "# tensor_node_feature = np.array(tensor_node_feature)\n",
    "# tensor_node_feature.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target value \n",
    "# pivot_table_for_target_value = merged_data_final.pivot_table(index='ORIGIN',columns='Hour',values='TRAFFIC FLOW').fillna(0)\n",
    "# list_target_value = tl.tensor(pivot_table_for_target_value).reshape(17,16,1)\n",
    "# tensor_target_value = tf.convert_to_tensor(list_target_value)\n",
    "# tensor_target_value = tf.transpose(tensor_target_value, perm=[1, 0, 2])\n",
    "# tensor_target_value = np.array(tensor_target_value)\n",
    "# tensor_target_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ten_target_value = []\n",
    "# grp_date = merged_data_final.groupby(['ETD_DATE'])\n",
    "# for i, df in grp_date:\n",
    "#     adj_matrix_target = np.zeros((51))\n",
    "#     for index, row in df.iterrows():\n",
    "#         adj_matrix_target[int(row['ORIGIN'])] = adj_matrix_target[int(row['ORIGIN'])] + row['TRAFFIC FLOW']\n",
    "#     ten_target_value.append(tl.tensor(adj_matrix_target))\n",
    "# tensor_target_value = tf.convert_to_tensor(ten_target_value)\n",
    "# tensor_target_value = np.array(tensor_target_value).reshape(183,51,1)\n",
    "# tensor_target_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "\n",
    "# tensor_node_feature = scale_data(tensor_node_feature)\n",
    "# tensor_graph_data = scale_data(tensor_graph_data)\n",
    "# tensor_target_value = scale_data(tensor_target_value)\n",
    "\n",
    "# scaler1 = MinMaxScaler()\n",
    "# scaler2 = MinMaxScaler()\n",
    "# scaler3 = MinMaxScaler()\n",
    "\n",
    "# reshaped_arr = tensor_target_value.reshape((-1, tensor_target_value.shape[-1]))\n",
    "# scaler3.fit(reshaped_arr)\n",
    "# scaled_arr_d = scaler3.inverse_transform(scaled_arr)\n",
    "# scaled_arr_d = tensor_target_value.reshape(tensor_target_value.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANGSHUB\\AppData\\Local\\Temp\\ipykernel_9368\\810228460.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  land_use[land_use['STOPS'].isin(unique_values)==False][['COMMERCIAL','PUBLIC_and_SEMI_PUBLIC','INDUSTRIAL','RESIDENTIAL','PARKS','PUBLIC_UTILITIES']] = 0\n"
     ]
    }
   ],
   "source": [
    "tensor_graph_data,tensor_node_feature,tensor_target_value = data_prepare(df_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2688, 51, 51), (2688, 51, 6), (2688, 51, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_graph_data.shape,tensor_node_feature.shape,tensor_target_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_nodes = 51\n",
    "# num_features = 6\n",
    "# num_timesteps = 2688\n",
    "\n",
    "# random_indices_1 = np.random.choice(2688, size=536, replace=False)\n",
    "# all_indices = np.arange(2688)\n",
    "# random_indices_2 = np.random.choice(np.setdiff1d(all_indices, random_indices_1), size=2151, replace=False)\n",
    "\n",
    "\n",
    "# train_data = {\"adj_matrix\": tensor_graph_data[random_indices_2,:,:], \"node_features\": tensor_node_feature[random_indices_2,:,:]}\n",
    "# train_targets = tensor_target_value[random_indices_2,:,:]\n",
    "# test_data = {\"adj_matrix\": tensor_graph_data[random_indices_1,:,:], \"node_features\": tensor_node_feature[random_indices_1,:,:]}\n",
    "# test_targets = tensor_target_value[random_indices_1,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 51\n",
    "num_features = 6\n",
    "num_timesteps = 2688\n",
    "train_data = {\"adj_matrix\": tensor_graph_data[:2151], \"node_features\": tensor_node_feature[:2151]}\n",
    "train_targets = tensor_target_value[1:2152].astype(np.int64)\n",
    "test_data = {\"adj_matrix\": tensor_graph_data[2151:2687], \"node_features\": tensor_node_feature[2151:2687]}\n",
    "test_targets = tensor_target_value[2152:].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "68/68 [==============================] - 10s 69ms/step - loss: 3.6445 - val_loss: 2.8214\n",
      "Epoch 2/200\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 2.3199 - val_loss: 2.4654\n",
      "Epoch 3/200\n",
      "68/68 [==============================] - 3s 49ms/step - loss: 2.2322 - val_loss: 2.6052\n",
      "Epoch 4/200\n",
      "68/68 [==============================] - 3s 49ms/step - loss: 2.1956 - val_loss: 2.3331\n",
      "Epoch 5/200\n",
      "68/68 [==============================] - 3s 50ms/step - loss: 2.1169 - val_loss: 2.3211\n",
      "Epoch 6/200\n",
      "68/68 [==============================] - 3s 50ms/step - loss: 2.1119 - val_loss: 2.2681\n",
      "Epoch 7/200\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 2.0686 - val_loss: 2.2823\n",
      "Epoch 8/200\n",
      "68/68 [==============================] - 3s 49ms/step - loss: 2.0436 - val_loss: 2.2440\n",
      "Epoch 9/200\n",
      "68/68 [==============================] - 4s 55ms/step - loss: 2.0294 - val_loss: 2.1930\n",
      "Epoch 10/200\n",
      "68/68 [==============================] - 4s 54ms/step - loss: 1.9432 - val_loss: 2.0307\n",
      "Epoch 11/200\n",
      "68/68 [==============================] - 3s 52ms/step - loss: 1.8827 - val_loss: 2.0784\n",
      "Epoch 12/200\n",
      "68/68 [==============================] - 4s 53ms/step - loss: 1.8601 - val_loss: 2.0687\n",
      "Epoch 13/200\n",
      "68/68 [==============================] - 3s 50ms/step - loss: 1.8445 - val_loss: 2.0077\n",
      "Epoch 14/200\n",
      "68/68 [==============================] - 3s 52ms/step - loss: 1.8431 - val_loss: 1.9813\n",
      "Epoch 15/200\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 1.8279 - val_loss: 2.0299\n",
      "Epoch 16/200\n",
      "68/68 [==============================] - 3s 47ms/step - loss: 1.8239 - val_loss: 2.0140\n",
      "Epoch 17/200\n",
      "68/68 [==============================] - 3s 50ms/step - loss: 1.8254 - val_loss: 2.0053\n",
      "Epoch 18/200\n",
      "68/68 [==============================] - 3s 50ms/step - loss: 1.8175 - val_loss: 2.0350\n",
      "Epoch 19/200\n",
      "68/68 [==============================] - 3s 49ms/step - loss: 1.8043 - val_loss: 2.0417\n",
      "Epoch 20/200\n",
      "68/68 [==============================] - 4s 53ms/step - loss: 1.8111 - val_loss: 2.0519\n",
      "Epoch 21/200\n",
      "68/68 [==============================] - 4s 54ms/step - loss: 1.7986 - val_loss: 2.0014\n",
      "Epoch 22/200\n",
      "68/68 [==============================] - 3s 48ms/step - loss: 1.7768 - val_loss: 1.9948\n",
      "Epoch 23/200\n",
      "68/68 [==============================] - 3s 50ms/step - loss: 1.7902 - val_loss: 1.9842\n",
      "Epoch 24/200\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 1.7683 - val_loss: 1.9657\n",
      "Epoch 25/200\n",
      "68/68 [==============================] - 3s 50ms/step - loss: 1.7609 - val_loss: 1.9819\n",
      "Epoch 26/200\n",
      "68/68 [==============================] - 3s 48ms/step - loss: 1.7559 - val_loss: 1.9750\n",
      "Epoch 27/200\n",
      "68/68 [==============================] - 3s 51ms/step - loss: 1.7549 - val_loss: 2.1649\n",
      "Epoch 28/200\n",
      "68/68 [==============================] - 4s 53ms/step - loss: 1.7630 - val_loss: 1.9596\n",
      "Epoch 29/200\n",
      "68/68 [==============================] - 3s 51ms/step - loss: 1.7532 - val_loss: 1.9887\n",
      "Epoch 30/200\n",
      "68/68 [==============================] - 4s 54ms/step - loss: 1.7417 - val_loss: 1.9648\n",
      "Epoch 31/200\n",
      "68/68 [==============================] - 3s 52ms/step - loss: 1.7540 - val_loss: 2.0007\n",
      "Epoch 32/200\n",
      "68/68 [==============================] - 3s 51ms/step - loss: 1.7589 - val_loss: 1.9474\n",
      "Epoch 33/200\n",
      "68/68 [==============================] - 3s 48ms/step - loss: 1.7371 - val_loss: 1.9260\n",
      "Epoch 34/200\n",
      "68/68 [==============================] - 3s 51ms/step - loss: 1.7358 - val_loss: 1.9463\n",
      "Epoch 35/200\n",
      "68/68 [==============================] - 3s 48ms/step - loss: 1.7193 - val_loss: 2.0088\n",
      "Epoch 36/200\n",
      "68/68 [==============================] - 3s 48ms/step - loss: 1.7260 - val_loss: 1.9773\n",
      "Epoch 37/200\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 1.7143 - val_loss: 1.9640\n",
      "Epoch 38/200\n",
      "68/68 [==============================] - 3s 49ms/step - loss: 1.7134 - val_loss: 1.9419\n",
      "Epoch 39/200\n",
      "68/68 [==============================] - 3s 52ms/step - loss: 1.7085 - val_loss: 1.9803\n",
      "Epoch 40/200\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 1.7356 - val_loss: 1.9283\n",
      "Epoch 41/200\n",
      "68/68 [==============================] - 4s 54ms/step - loss: 1.7010 - val_loss: 1.9488\n",
      "Epoch 42/200\n",
      "68/68 [==============================] - 3s 51ms/step - loss: 1.6843 - val_loss: 1.9679\n",
      "Epoch 43/200\n",
      "68/68 [==============================] - 3s 48ms/step - loss: 1.7019 - val_loss: 1.9911\n",
      "Epoch 44/200\n",
      "68/68 [==============================] - 4s 54ms/step - loss: 1.6956 - val_loss: 1.9580\n",
      "Epoch 45/200\n",
      "68/68 [==============================] - 3s 49ms/step - loss: 1.6951 - val_loss: 2.0291\n",
      "Epoch 46/200\n",
      "68/68 [==============================] - 3s 51ms/step - loss: 1.7251 - val_loss: 2.0069\n",
      "Epoch 47/200\n",
      "68/68 [==============================] - 3s 50ms/step - loss: 1.6900 - val_loss: 1.9805\n",
      "Epoch 48/200\n",
      "68/68 [==============================] - 3s 50ms/step - loss: 1.6871 - val_loss: 1.9300\n",
      "Epoch 49/200\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 1.6812 - val_loss: 2.0343\n",
      "Epoch 50/200\n",
      "68/68 [==============================] - 3s 48ms/step - loss: 1.6579 - val_loss: 1.9836\n",
      "Epoch 51/200\n",
      "68/68 [==============================] - 3s 51ms/step - loss: 1.6689 - val_loss: 1.9418\n",
      "Epoch 52/200\n",
      "68/68 [==============================] - 3s 50ms/step - loss: 1.6541 - val_loss: 1.9422\n",
      "Epoch 53/200\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 1.6730 - val_loss: 2.0350\n",
      "Epoch 54/200\n",
      "68/68 [==============================] - 3s 49ms/step - loss: 1.6784 - val_loss: 1.9309\n",
      "Epoch 55/200\n",
      "68/68 [==============================] - 4s 54ms/step - loss: 1.6512 - val_loss: 1.9267\n",
      "Epoch 56/200\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 1.6382 - val_loss: 2.0248\n",
      "Epoch 57/200\n",
      "68/68 [==============================] - 3s 49ms/step - loss: 1.6409 - val_loss: 1.9639\n",
      "Epoch 58/200\n",
      "68/68 [==============================] - 3s 50ms/step - loss: 1.6364 - val_loss: 1.9516\n",
      "Epoch 59/200\n",
      "68/68 [==============================] - 3s 49ms/step - loss: 1.6517 - val_loss: 1.9459\n",
      "Epoch 60/200\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 1.6458 - val_loss: 2.0554\n",
      "Epoch 61/200\n",
      "68/68 [==============================] - 4s 52ms/step - loss: 1.6309 - val_loss: 1.9298\n",
      "Epoch 62/200\n",
      "68/68 [==============================] - 3s 50ms/step - loss: 1.6201 - val_loss: 1.9559\n",
      "Epoch 63/200\n",
      "68/68 [==============================] - 3s 51ms/step - loss: 1.6226 - val_loss: 1.9653\n",
      "Epoch 64/200\n",
      "68/68 [==============================] - 3s 38ms/step - loss: 1.6111 - val_loss: 2.0138\n",
      "Epoch 65/200\n",
      "68/68 [==============================] - 2s 29ms/step - loss: 1.6185 - val_loss: 1.9718\n",
      "Epoch 66/200\n",
      "68/68 [==============================] - 2s 25ms/step - loss: 1.6198 - val_loss: 1.9195\n",
      "Epoch 67/200\n",
      "68/68 [==============================] - 2s 26ms/step - loss: 1.6110 - val_loss: 2.0992\n",
      "Epoch 68/200\n",
      "68/68 [==============================] - 2s 25ms/step - loss: 1.6221 - val_loss: 1.9745\n",
      "Epoch 69/200\n",
      "68/68 [==============================] - 2s 25ms/step - loss: 1.6165 - val_loss: 1.9934\n",
      "Epoch 70/200\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.5983 - val_loss: 1.9084\n",
      "Epoch 71/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.6279 - val_loss: 1.9860\n",
      "Epoch 72/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.5946 - val_loss: 1.9301\n",
      "Epoch 73/200\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.5917 - val_loss: 1.9335\n",
      "Epoch 74/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.6063 - val_loss: 1.9519\n",
      "Epoch 75/200\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.5770 - val_loss: 1.9479\n",
      "Epoch 76/200\n",
      "68/68 [==============================] - 2s 25ms/step - loss: 1.5928 - val_loss: 1.9546\n",
      "Epoch 77/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.5906 - val_loss: 1.9499\n",
      "Epoch 78/200\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.5784 - val_loss: 2.0199\n",
      "Epoch 79/200\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.5721 - val_loss: 2.0036\n",
      "Epoch 80/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.5878 - val_loss: 1.9997\n",
      "Epoch 81/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.5743 - val_loss: 1.9919\n",
      "Epoch 82/200\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.5693 - val_loss: 1.9335\n",
      "Epoch 83/200\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.5618 - val_loss: 1.9770\n",
      "Epoch 84/200\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.5666 - val_loss: 2.0063\n",
      "Epoch 85/200\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.5729 - val_loss: 1.9711\n",
      "Epoch 86/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.5517 - val_loss: 1.9834\n",
      "Epoch 87/200\n",
      "68/68 [==============================] - 1s 22ms/step - loss: 1.5671 - val_loss: 1.9804\n",
      "Epoch 88/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.5514 - val_loss: 1.9949\n",
      "Epoch 89/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.5508 - val_loss: 1.9796\n",
      "Epoch 90/200\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.5571 - val_loss: 1.9755\n",
      "Epoch 91/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.5530 - val_loss: 1.9655\n",
      "Epoch 92/200\n",
      "68/68 [==============================] - 2s 31ms/step - loss: 1.5385 - val_loss: 2.0685\n",
      "Epoch 93/200\n",
      "68/68 [==============================] - 2s 25ms/step - loss: 1.5466 - val_loss: 1.9859\n",
      "Epoch 94/200\n",
      "68/68 [==============================] - 1s 22ms/step - loss: 1.5610 - val_loss: 1.9492\n",
      "Epoch 95/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.5429 - val_loss: 1.9354\n",
      "Epoch 96/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.5475 - val_loss: 1.9883\n",
      "Epoch 97/200\n",
      "68/68 [==============================] - 2s 24ms/step - loss: 1.5764 - val_loss: 1.9483\n",
      "Epoch 98/200\n",
      "68/68 [==============================] - 1s 22ms/step - loss: 1.5348 - val_loss: 1.9373\n",
      "Epoch 99/200\n",
      "68/68 [==============================] - 1s 20ms/step - loss: 1.5337 - val_loss: 1.9827\n",
      "Epoch 100/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.5237 - val_loss: 1.9700\n",
      "Epoch 101/200\n",
      "68/68 [==============================] - 2s 23ms/step - loss: 1.5492 - val_loss: 1.9736\n",
      "Epoch 102/200\n",
      "68/68 [==============================] - 2s 22ms/step - loss: 1.5360 - val_loss: 1.9454\n",
      "Epoch 103/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.5195 - val_loss: 1.9196\n",
      "Epoch 104/200\n",
      "68/68 [==============================] - 1s 20ms/step - loss: 1.5231 - val_loss: 2.0642\n",
      "Epoch 105/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.5314 - val_loss: 2.0181\n",
      "Epoch 106/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.5279 - val_loss: 1.9865\n",
      "Epoch 107/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.5222 - val_loss: 1.9384\n",
      "Epoch 108/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.5274 - val_loss: 1.9277\n",
      "Epoch 109/200\n",
      "68/68 [==============================] - 1s 21ms/step - loss: 1.5179 - val_loss: 1.9561\n",
      "Epoch 110/200\n",
      "68/68 [==============================] - 1s 20ms/step - loss: 1.5077 - val_loss: 1.9979\n",
      "Epoch 111/200\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.4952 - val_loss: 1.9475\n",
      "Epoch 112/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.5105 - val_loss: 1.9840\n",
      "Epoch 113/200\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.5464 - val_loss: 2.0510\n",
      "Epoch 114/200\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.5329 - val_loss: 1.9539\n",
      "Epoch 115/200\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.5206 - val_loss: 2.0186\n",
      "Epoch 116/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.5168 - val_loss: 1.9470\n",
      "Epoch 117/200\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.5144 - val_loss: 2.0108\n",
      "Epoch 118/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.5175 - val_loss: 2.0208\n",
      "Epoch 119/200\n",
      "68/68 [==============================] - 2s 23ms/step - loss: 1.5116 - val_loss: 1.9672\n",
      "Epoch 120/200\n",
      "68/68 [==============================] - 1s 22ms/step - loss: 1.4825 - val_loss: 1.9559\n",
      "Epoch 121/200\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.4989 - val_loss: 2.0019\n",
      "Epoch 122/200\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.4946 - val_loss: 1.9441\n",
      "Epoch 123/200\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.5018 - val_loss: 1.9590\n",
      "Epoch 124/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.4795 - val_loss: 1.9326\n",
      "Epoch 125/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.4701 - val_loss: 1.9408\n",
      "Epoch 126/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.4828 - val_loss: 1.9145\n",
      "Epoch 127/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.4729 - val_loss: 1.9347\n",
      "Epoch 128/200\n",
      "68/68 [==============================] - 1s 20ms/step - loss: 1.4828 - val_loss: 1.9393\n",
      "Epoch 129/200\n",
      "68/68 [==============================] - 1s 22ms/step - loss: 1.4842 - val_loss: 1.9395\n",
      "Epoch 130/200\n",
      "68/68 [==============================] - 1s 21ms/step - loss: 1.4816 - val_loss: 1.9496\n",
      "Epoch 131/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.4946 - val_loss: 1.9508\n",
      "Epoch 132/200\n",
      "68/68 [==============================] - 1s 21ms/step - loss: 1.4998 - val_loss: 2.0182\n",
      "Epoch 133/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.4922 - val_loss: 1.9663\n",
      "Epoch 134/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.4619 - val_loss: 1.9569\n",
      "Epoch 135/200\n",
      "68/68 [==============================] - 2s 22ms/step - loss: 1.4689 - val_loss: 1.9438\n",
      "Epoch 136/200\n",
      "68/68 [==============================] - 1s 21ms/step - loss: 1.4629 - val_loss: 1.9685\n",
      "Epoch 137/200\n",
      "68/68 [==============================] - 2s 22ms/step - loss: 1.4653 - val_loss: 1.9638\n",
      "Epoch 138/200\n",
      "68/68 [==============================] - 2s 22ms/step - loss: 1.4754 - val_loss: 1.9829\n",
      "Epoch 139/200\n",
      "68/68 [==============================] - 2s 23ms/step - loss: 1.4749 - val_loss: 1.9958\n",
      "Epoch 140/200\n",
      "68/68 [==============================] - 1s 20ms/step - loss: 1.4758 - val_loss: 1.9985\n",
      "Epoch 141/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.4559 - val_loss: 1.9876\n",
      "Epoch 142/200\n",
      "68/68 [==============================] - 1s 21ms/step - loss: 1.4682 - val_loss: 1.9644\n",
      "Epoch 143/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.4485 - val_loss: 1.9711\n",
      "Epoch 144/200\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.4571 - val_loss: 1.9653\n",
      "Epoch 145/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.4781 - val_loss: 1.9888\n",
      "Epoch 146/200\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.4615 - val_loss: 1.9472\n",
      "Epoch 147/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.4638 - val_loss: 2.0026\n",
      "Epoch 148/200\n",
      "68/68 [==============================] - 2s 30ms/step - loss: 1.4491 - val_loss: 2.0472\n",
      "Epoch 149/200\n",
      "68/68 [==============================] - 2s 27ms/step - loss: 1.4433 - val_loss: 1.9695\n",
      "Epoch 150/200\n",
      "68/68 [==============================] - 2s 25ms/step - loss: 1.4808 - val_loss: 1.9685\n",
      "Epoch 151/200\n",
      "68/68 [==============================] - 2s 23ms/step - loss: 1.4630 - val_loss: 1.9682\n",
      "Epoch 152/200\n",
      "68/68 [==============================] - 1s 21ms/step - loss: 1.4352 - val_loss: 1.9543\n",
      "Epoch 153/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.4321 - val_loss: 1.9658\n",
      "Epoch 154/200\n",
      "68/68 [==============================] - 1s 21ms/step - loss: 1.4445 - val_loss: 1.9891\n",
      "Epoch 155/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.4374 - val_loss: 2.0091\n",
      "Epoch 156/200\n",
      "68/68 [==============================] - 1s 20ms/step - loss: 1.4377 - val_loss: 1.9330\n",
      "Epoch 157/200\n",
      "68/68 [==============================] - 2s 22ms/step - loss: 1.4335 - val_loss: 2.0092\n",
      "Epoch 158/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.4242 - val_loss: 1.9803\n",
      "Epoch 159/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.4403 - val_loss: 1.9926\n",
      "Epoch 160/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.4268 - val_loss: 1.9831\n",
      "Epoch 161/200\n",
      "68/68 [==============================] - 2s 22ms/step - loss: 1.4279 - val_loss: 2.0088\n",
      "Epoch 162/200\n",
      "68/68 [==============================] - 1s 21ms/step - loss: 1.4172 - val_loss: 1.9479\n",
      "Epoch 163/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.4288 - val_loss: 1.9485\n",
      "Epoch 164/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.4271 - val_loss: 2.0243\n",
      "Epoch 165/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.4308 - val_loss: 1.9781\n",
      "Epoch 166/200\n",
      "68/68 [==============================] - 1s 20ms/step - loss: 1.4235 - val_loss: 1.9737\n",
      "Epoch 167/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.4257 - val_loss: 1.9510\n",
      "Epoch 168/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.4098 - val_loss: 1.9519\n",
      "Epoch 169/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.4167 - val_loss: 1.9734\n",
      "Epoch 170/200\n",
      "68/68 [==============================] - 1s 20ms/step - loss: 1.4139 - val_loss: 2.0037\n",
      "Epoch 171/200\n",
      "68/68 [==============================] - 1s 22ms/step - loss: 1.4241 - val_loss: 1.9578\n",
      "Epoch 172/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.4079 - val_loss: 2.0103\n",
      "Epoch 173/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.4128 - val_loss: 2.0392\n",
      "Epoch 174/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.4079 - val_loss: 1.9632\n",
      "Epoch 175/200\n",
      "68/68 [==============================] - 2s 24ms/step - loss: 1.4079 - val_loss: 1.9428\n",
      "Epoch 176/200\n",
      "68/68 [==============================] - 2s 26ms/step - loss: 1.3985 - val_loss: 1.9567\n",
      "Epoch 177/200\n",
      "68/68 [==============================] - 1s 22ms/step - loss: 1.4081 - val_loss: 1.9684\n",
      "Epoch 178/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.4104 - val_loss: 1.9496\n",
      "Epoch 179/200\n",
      "68/68 [==============================] - 2s 25ms/step - loss: 1.4091 - val_loss: 1.9863\n",
      "Epoch 180/200\n",
      "68/68 [==============================] - 2s 24ms/step - loss: 1.4101 - val_loss: 1.9729\n",
      "Epoch 181/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.3892 - val_loss: 1.9393\n",
      "Epoch 182/200\n",
      "68/68 [==============================] - 1s 19ms/step - loss: 1.4136 - val_loss: 1.9909\n",
      "Epoch 183/200\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.4044 - val_loss: 1.9570\n",
      "Epoch 184/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.3855 - val_loss: 1.9828\n",
      "Epoch 185/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.3946 - val_loss: 1.9514\n",
      "Epoch 186/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.3944 - val_loss: 2.0200\n",
      "Epoch 187/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.3976 - val_loss: 1.9811\n",
      "Epoch 188/200\n",
      "68/68 [==============================] - 1s 14ms/step - loss: 1.3991 - val_loss: 1.9785\n",
      "Epoch 189/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.3923 - val_loss: 1.9887\n",
      "Epoch 190/200\n",
      "68/68 [==============================] - 1s 16ms/step - loss: 1.4050 - val_loss: 1.9620\n",
      "Epoch 191/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.3809 - val_loss: 2.0050\n",
      "Epoch 192/200\n",
      "68/68 [==============================] - 2s 26ms/step - loss: 1.3934 - val_loss: 2.0091\n",
      "Epoch 193/200\n",
      "68/68 [==============================] - 1s 18ms/step - loss: 1.3864 - val_loss: 1.9865\n",
      "Epoch 194/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.4069 - val_loss: 2.0448\n",
      "Epoch 195/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.3825 - val_loss: 1.9834\n",
      "Epoch 196/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.3849 - val_loss: 2.0230\n",
      "Epoch 197/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.3899 - val_loss: 2.0210\n",
      "Epoch 198/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.3804 - val_loss: 2.0188\n",
      "Epoch 199/200\n",
      "68/68 [==============================] - 1s 17ms/step - loss: 1.3829 - val_loss: 2.0308\n",
      "Epoch 200/200\n",
      "68/68 [==============================] - 1s 15ms/step - loss: 1.3821 - val_loss: 2.0186\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from spektral.layers import GCNConv\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "class GCN(tf.keras.Model):\n",
    "    def __init__(self, num_features, num_timesteps,num_nodes):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.conv1 = GCNConv(128 ,activation=\"relu\")\n",
    "        self.conv2 = GCNConv(64, activation=\"relu\")\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(128, activation=\"relu\")\n",
    "        self.dense2 = tf.keras.layers.Dense(64, activation=\"relu\")\n",
    "        self.dense3 = tf.keras.layers.Dense(num_nodes)\n",
    "\n",
    "        self.adj_shape = (num_timesteps, None, None)\n",
    "        self.features_shape = (num_timesteps, None, num_features)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs[\"node_features\"], inputs[\"adj_matrix\"]\n",
    "        a = tf.transpose(a, perm=[0, 2, 1])\n",
    "        a = tf.linalg.matmul(a, tf.transpose(a, perm=[0, 2, 1]))\n",
    "        x = self.conv1([x, a])\n",
    "        x = self.conv2([x, a])\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# class GCN(tf.keras.Model):\n",
    "#     def __init__(self, num_features, num_timesteps, num_nodes, dropout_rate=0.2):\n",
    "#         super(GCN, self).__init__()\n",
    "\n",
    "#         self.conv1 = GCNConv(256, activation=\"relu\")\n",
    "#         self.conv2 = GCNConv(128, activation=\"relu\")\n",
    "#         self.conv3 = GCNConv(64, activation=\"relu\")\n",
    "#         self.flatten = tf.keras.layers.Flatten()\n",
    "#         self.dense1 = tf.keras.layers.Dense(32, activation=\"relu\")\n",
    "#         self.dense2 = tf.keras.layers.Dense(num_nodes*1, activation=\"linear\")\n",
    "\n",
    "#         self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "#         self.adj_shape = (num_timesteps, None, None)\n",
    "#         self.features_shape = (num_timesteps, None, num_features)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         x, a = inputs[\"node_features\"], inputs[\"adj_matrix\"]\n",
    "#         a = tf.transpose(a, perm=[0, 2, 1])\n",
    "#         a = tf.linalg.matmul(a, tf.transpose(a, perm=[0, 2, 1]))\n",
    "#         x = self.conv1([x, a])\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.conv2([x, a])\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.conv3([x, a])\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.dense2(x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from spektral.layers import GCNConv\n",
    "# from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# class GCN(tf.keras.Model):\n",
    "#     def __init__(self, num_features, num_timesteps, num_nodes, dropout_rate=0.1):\n",
    "#         super(GCN, self).__init__()\n",
    "\n",
    "#         self.conv1 = GCNConv(256, activation=\"relu\")\n",
    "#         self.conv2 = GCNConv(128, activation=\"relu\")\n",
    "#         self.conv3 = GCNConv(64, activation=\"relu\")\n",
    "#         self.flatten = tf.keras.layers.Flatten()\n",
    "#         self.dense1 = tf.keras.layers.Dense(64, activation=\"relu\")\n",
    "#         self.dense2 = tf.keras.layers.Dense(32, activation=\"relu\")\n",
    "#         self.dense3 = tf.keras.layers.Dense(num_nodes*1)\n",
    "\n",
    "#         self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "#         self.adj_shape = (num_timesteps, None, None)\n",
    "#         self.features_shape = (num_timesteps, None, num_features)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         x, a = inputs[\"node_features\"], inputs[\"adj_matrix\"]\n",
    "#         a = tf.transpose(a, perm=[0, 2, 1])\n",
    "#         a = tf.linalg.matmul(a, tf.transpose(a, perm=[0, 2, 1]))\n",
    "#         x = self.conv1([x, a])\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.conv2([x, a])\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.conv3([x, a])\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.dense2(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.dense3(x)\n",
    "#         return x\n",
    "\n",
    "model = GCN(num_features=num_features, num_timesteps=num_timesteps,num_nodes=num_nodes)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss=\"mae\" )\n",
    "history = model.fit(train_data, train_targets, epochs=200, batch_size=32, validation_data=(test_data, test_targets))\n",
    "\n",
    "# Get training and validation loss from the history object\n",
    "train_loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "# Create a list of epoch numbers\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(train_loss, label=\"Training Loss\")\n",
    "sns.lineplot(val_loss, label=\"Validation Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3730345964431763"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train_data, train_targets, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(train_data).astype(np.int64)\n",
    "train_targets = train_targets.reshape(2151,51).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  0.09568945743483816\n",
      "MAE :  1.348374217190363\n",
      "MSE :  19.372147929371657\n",
      "RMSE :  4.401380230038261\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error , mean_absolute_error , mean_squared_error\n",
    "import math\n",
    "print(\"MAPE : \" ,mean_absolute_percentage_error(train_targets[0:10],predictions[0:10]))\n",
    "print(\"MAE : \" ,mean_absolute_error(train_targets,predictions))\n",
    "print(\"MSE : \" ,mean_squared_error(train_targets,predictions))\n",
    "print(\"RMSE : \", math.sqrt(mean_squared_error(train_targets,predictions)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pickle.dump(model, open('saved/model.p', 'wb'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION FOR TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare(df_route):\n",
    "    df_route = df_route[['ETD_DATE','Hour','ORIGIN','DESTINATION']]\n",
    "    df_route_unique = pd.DataFrame(df_route.value_counts())\n",
    "    df_route_unique = df_route_unique.reset_index()\n",
    "    df_route_unique.rename(columns={0:'TRAFFIC FLOW'},inplace=True)\n",
    "    land_use = pd.read_csv(\"Land_Use.csv\")\n",
    "    land_use.fillna(0,inplace=True)\n",
    "    # merged_data_final = pd.merge(df_route_unique, land_use, left_on='ORIGIN', right_on='STOPS')\n",
    "    # merged_data_final.drop(columns=['STOPS'],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    ten_graph_data = []\n",
    "    grp_hr = df_route_unique.groupby(['ETD_DATE','Hour'])\n",
    "    for i, df in grp_hr:\n",
    "        adj_matrix = np.zeros((51,51))\n",
    "        for index, row in df.iterrows():\n",
    "            adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] = adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] + int(row['TRAFFIC FLOW'])\n",
    "        ten_graph_data.append(tl.tensor(adj_matrix).reshape(51,51))\n",
    "    tensor_graph_data = tf.convert_to_tensor(ten_graph_data)\n",
    "    tensor_graph_data = np.array(tensor_graph_data)\n",
    "\n",
    "\n",
    "    # unique_values = pd.unique(merged_data_final[['ORIGIN','DESTINATION']].values.ravel('K'))\n",
    "    # land_use[land_use['STOPS'].isin(unique_values)==False][['COMMERCIAL','PUBLIC_and_SEMI_PUBLIC','INDUSTRIAL','RESIDENTIAL','PARKS','PUBLIC_UTILITIES']] = 0\n",
    "\n",
    "    pivot_table_for_node_features = np.array(land_use[['COMMERCIAL', 'PUBLIC_and_SEMI_PUBLIC', 'INDUSTRIAL', 'RESIDENTIAL','PARKS', 'PUBLIC_UTILITIES']])\n",
    "    list_node_features = []\n",
    "    for i in range(len(tensor_graph_data)):\n",
    "            list_node_features.append(pivot_table_for_node_features)\n",
    "    tensor_node_feature = tf.convert_to_tensor(list_node_features)\n",
    "    tensor_node_feature = np.array(tensor_node_feature)\n",
    "\n",
    "\n",
    "\n",
    "    ten_target_value = []\n",
    "    grp_date = df_route_unique.groupby(['ETD_DATE','Hour'])\n",
    "    for i, df in grp_date:\n",
    "        adj_matrix_target = np.zeros((51))\n",
    "        for index, row in df.iterrows():\n",
    "            adj_matrix_target[int(row['ORIGIN'])] = adj_matrix_target[int(row['ORIGIN'])] + row['TRAFFIC FLOW']\n",
    "        ten_target_value.append(tl.tensor(adj_matrix_target))\n",
    "    tensor_target_value = tf.convert_to_tensor(ten_target_value)\n",
    "    tensor_target_value = np.array(tensor_target_value).reshape(len(tensor_graph_data),51,1)\n",
    "\n",
    "    tensor_node_feature = scale_data(tensor_node_feature)\n",
    "    tensor_graph_data = scale_data(tensor_graph_data)\n",
    "\n",
    "\n",
    "    return tensor_graph_data,tensor_node_feature,tensor_target_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING WITH NEW DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "U102 = pd.read_excel('route_data/U106.xlsx',index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANGSHUB\\AppData\\Local\\Temp\\ipykernel_12980\\3745735706.py:15: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for i, df in grp_hr:\n",
      "C:\\Users\\HIMANGSHUB\\AppData\\Local\\Temp\\ipykernel_12980\\3745735706.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  land_use[land_use['STOPS'].isin(unique_values)==False][['COMMERCIAL','PUBLIC_and_SEMI_PUBLIC','INDUSTRIAL','RESIDENTIAL','PARKS','PUBLIC_UTILITIES']] = 0\n",
      "C:\\Users\\HIMANGSHUB\\AppData\\Local\\Temp\\ipykernel_12980\\3745735706.py:38: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for i, df in grp_date:\n"
     ]
    }
   ],
   "source": [
    "tensor_graph_data_1,tensor_node_feature_1,tensor_target_value_1 = data_prepare(U102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.67403314917127"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_102 = {\"adj_matrix\": tensor_graph_data_1[1:182], \"node_features\": tensor_node_feature_1[1:182]}\n",
    "test_targets_102 = tensor_target_value_1[2:183].reshape(-1,51).astype(np.int64)\n",
    "\n",
    "predictions = model.predict(test_data_102).astype(np.int64)\n",
    "mapeTensor = tf.keras.losses.mae(test_targets_102,predictions)\n",
    "np.mean(mapeTensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL WITH TIMESTAMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 7\n",
    "\n",
    "# Create input/output pairs\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(tensor_graph_data) - window_size):\n",
    "    X.append(tensor_graph_data[i:i+window_size])\n",
    "    y.append(tensor_graph_data[i+window_size])\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 17, 17)"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout ,Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanSquaredError\n",
    "from spektral.layers import GCNConv\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (7, 17, 17)\n",
    "\n",
    "# Define the model inputs\n",
    "x_in = Input(shape=input_shape)\n",
    "x = Lambda(lambda x: x[..., tf.newaxis])(x_in)  # Add an extra dimension\n",
    "# Build the GCNConv model\n",
    "x = GCNConv(32, activation=\"relu\")([x_in])\n",
    "x = GCNConv(64, activation=\"relu\")([x])\n",
    "x = GCNConv(128, activation=\"relu\")([x])\n",
    "x = Dropout(0.5)(x)\n",
    "x = GCNConv(17, activation=\"linear\")([x])\n",
    "\n",
    "# Define the model outputs\n",
    "x_out = x\n",
    "\n",
    "# Build the model\n",
    "model = Model(inputs=x_in, outputs=x_out)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=MeanSquaredError(),\n",
    "    metrics=[MeanSquaredError()],\n",
    ")\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "    \n",
    "# model = TGCN(num_timesteps=7, num_nodes=17)\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mae\")\n",
    "\n",
    "# history = model.fit(X, y, epochs=400, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras-tuner --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import layers\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from keras_tuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(hp):\n",
    "#     model = keras.Sequential()\n",
    "#     for i in range(hp.Int('num_layers', 2, 20)):\n",
    "#         model.add(GCNConv(128, activation=\"relu\"))\n",
    "#         model.add(GCNConv(64, activation=\"relu\"))\n",
    "#         model.add(GCNConv(32,activation=\"relu\"))\n",
    "#         model.add(layers.Flatten())\n",
    "#         model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "#                                                 min_value=24,\n",
    "#                                                 max_value=512,\n",
    "#                                                 step=32),\n",
    "#                                 activation='relu'))\n",
    "#         model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "#                                                 min_value=24,\n",
    "#                                                 max_value=512,\n",
    "#                                                 step=32),\n",
    "#                                 activation='relu'))\n",
    "#         model.add(layers.Dense(num_nodes*1))\n",
    "\n",
    "\n",
    "\n",
    "#     model.compile(\n",
    "#         optimizer=keras.optimizers.Adam(\n",
    "#             hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "#         loss= hp.Choice('loss' , ['mean_absolute_error','mean_squared_error']),\n",
    "#     metrics= hp.Choice('metrics' , ['mean_absolute_error','mean_squared_error']))\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner  = RandomSearch(\n",
    "#     build_model,\n",
    "#     objective=['val_mean_absolute_error','val_mean_squared_error'],\n",
    "#     max_trials=5,\n",
    "#     executions_per_trial=3,\n",
    "#     directory='Hyperparameter_tuning',\n",
    "#     project_name='Insurance estimator'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMO MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from spektral.layers import GCNConv\n",
    "# from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "\n",
    "# num_nodes = 17\n",
    "# num_features = 6\n",
    "# num_timesteps = 16\n",
    "\n",
    "# adj_matrix_data = np.random.randn(num_timesteps,num_nodes, num_nodes)\n",
    "# node_features_data = np.random.randn(num_timesteps,num_nodes, num_features)\n",
    "# target_data = np.random.randn(num_timesteps,num_nodes, 1)\n",
    "\n",
    "# print(adj_matrix_data.shape ,  node_features_data.shape , target_data.shape)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# train_data = {\"adj_matrix\": adj_matrix_data[:10], \"node_features\": node_features_data[:10]}\n",
    "# train_targets = target_data[:10]\n",
    "# test_data = {\"adj_matrix\": adj_matrix_data[10:], \"node_features\": node_features_data[10:]}\n",
    "# test_targets = target_data[10:]\n",
    "\n",
    "\n",
    "\n",
    "# class GCN(tf.keras.Model):\n",
    "#     def __init__(self, num_features, num_timesteps, dropout_rate=0.2):\n",
    "#         super(GCN, self).__init__()\n",
    "\n",
    "#         self.conv1 = GCNConv(64, activation=\"relu\")\n",
    "#         self.conv2 = GCNConv(32, activation=\"relu\")\n",
    "#         self.flatten = tf.keras.layers.Flatten()\n",
    "#         self.dense1 = tf.keras.layers.Dense(16, activation=\"relu\")\n",
    "#         self.dense2 = tf.keras.layers.Dense(num_nodes*1)\n",
    "\n",
    "#         self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "#         self.adj_shape = (num_timesteps, None, None)\n",
    "#         self.features_shape = (num_timesteps, None, num_features)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         x, a = inputs[\"node_features\"], inputs[\"adj_matrix\"]\n",
    "#         a = tf.transpose(a, perm=[0, 2, 1])\n",
    "#         a = tf.linalg.matmul(a, tf.transpose(a, perm=[0, 2, 1]))\n",
    "#         x = self.conv1([x, a])\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.conv2([x, a])\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.dense2(x)\n",
    "\n",
    "#         return x\n",
    "    \n",
    "# model = GCN(num_features=num_features, num_timesteps=num_timesteps)\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\" )\n",
    "# model.fit(train_data, train_targets, epochs=700, validation_data=(test_data, test_targets))\n",
    "# pre = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_nodes = 17\n",
    "# num_features = 6\n",
    "# num_timesteps = 16\n",
    "\n",
    "# adj_matrix_data = np.random.randn(num_nodes, num_nodes, num_timesteps)\n",
    "# node_features_data = np.random.randn(num_nodes, num_timesteps, num_features)\n",
    "# target_data = np.random.randn(num_nodes, num_timesteps, 1)\n",
    "\n",
    "# train_data = {\"adj_matrix\": adj_matrix_data[:2], \"node_features\": node_features_data[:2]}\n",
    "# train_targets = target_data[:2]\n",
    "# test_data = {\"adj_matrix\": adj_matrix_data[2:], \"node_features\": node_features_data[2:]}\n",
    "# test_targets = target_data[2:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input, Dense, GRU, Reshape, Concatenate, Conv2D, Flatten\n",
    "# from tensorflow.keras.models import Model\n",
    "\n",
    "# # Define the input shapes for the adjacency matrix and node features tensors\n",
    "# num_nodes = 17\n",
    "# num_features = 6\n",
    "# num_timesteps = 16\n",
    "\n",
    "# adj_matrix = Input(shape=(num_nodes, num_nodes, num_timesteps), name=\"adj_matrix\")\n",
    "# node_features = Input(shape=(num_nodes, num_timesteps, num_features), name=\"node_features\")\n",
    "\n",
    "# # Define the T-GCN layers that will process the input data\n",
    "# num_filters = 32\n",
    "# kernel_size = (1, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Generate example data for training and testing\n",
    "# import numpy as np\n",
    "\n",
    "# adj_matrix_data = np.random.randn(num_nodes, num_nodes, num_timesteps)\n",
    "# node_features_data = np.random.randn(num_nodes, num_timesteps, num_features)\n",
    "# target_data = np.random.randn(num_nodes, num_timesteps, 1)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# train_data = {\"adj_matrix\": adj_matrix_data[:2], \"node_features\": node_features_data[:2]}\n",
    "# train_targets = target_data[:2]\n",
    "# test_data = {\"adj_matrix\": adj_matrix_data[2:], \"node_features\": node_features_data[2:]}\n",
    "# test_targets = target_data[2:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Concatenate, Dense, Reshape, Dropout\n",
    "# from tensorflow.keras.models import Model\n",
    "# import numpy as np\n",
    "\n",
    "# # Define model hyperparameters\n",
    "# num_filters = 16\n",
    "# num_timesteps = 16\n",
    "# num_nodes = 17\n",
    "# num_features = 6\n",
    "\n",
    "\n",
    "# adj_matrix_data = np.random.randn(num_nodes, num_nodes, num_timesteps)\n",
    "# node_features_data = np.random.randn(num_nodes, num_timesteps, num_features)\n",
    "# target_data = np.random.randn(num_nodes, num_timesteps, 1)\n",
    "\n",
    "\n",
    "# # Define input layers\n",
    "# adj_matrix_input = Input(shape=(num_nodes, num_nodes, num_timesteps), name='adj_matrix_input')\n",
    "# node_features_input = Input(shape=(num_nodes, num_timesteps, num_features), name='node_features_input')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Define temporal convolutional layer\n",
    "# def temporal_conv_layer(x, adj_matrix, num_filters, kernel_size):\n",
    "#     # Add channel dimension to adjacency matrix\n",
    "#     adj_matrix = tf.expand_dims(adj_matrix, axis=-1)\n",
    "#     # Perform convolution on adjacency matrix\n",
    "#     adj_matrix = Conv2D(filters=num_filters, kernel_size=(1, kernel_size))(adj_matrix)\n",
    "#     adj_matrix = BatchNormalization()(adj_matrix)\n",
    "#     adj_matrix = Activation('relu')(adj_matrix)\n",
    "#     # Remove channel dimension from adjacency matrix\n",
    "#     adj_matrix = tf.squeeze(adj_matrix, axis=-1)\n",
    "#     # Perform multiplication between node features and adjacency matrix\n",
    "#     x = tf.linalg.matmul(adj_matrix, x) \n",
    "#     return x\n",
    "\n",
    "\n",
    "# # Define T-GCN model\n",
    "# x = node_features_input\n",
    "# for i in range(2):\n",
    "#     x = temporal_conv_layer(x, adj_matrix_input, num_filters, 2)\n",
    "#     x = BatchNormalization()(x)\n",
    "#     x = Activation('relu')(x)\n",
    "#     x = Dropout(0.5)(x)\n",
    "# x = tf.reduce_mean(x, axis=1)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# output = Dense(1)(x)\n",
    "\n",
    "# # Define model inputs and outputs\n",
    "# inputs = [adj_matrix_input, node_features_input]\n",
    "# model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# train_data = {\"adj_matrix\": adj_matrix_data[:2], \"node_features\": node_features_data[:2]}\n",
    "# train_targets = target_data[:2]\n",
    "# test_data = {\"adj_matrix\": adj_matrix_data[2:], \"node_features\": node_features_data[2:]}\n",
    "# test_targets = target_data[2:]\n",
    "\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(train_data, train_targets, validation_data=(test_data, test_targets), epochs=10, batch_size=2)\n",
    "\n",
    "# # Evaluate the model on the testing set\n",
    "# test_loss = model.evaluate(test_data, test_targets)\n",
    "# print(\"Test loss:\", test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorflow_addons as tfa\n",
    "\n",
    "# class TGCN(tf.keras.Model):\n",
    "#     def __init__(self, num_nodes, num_features, num_timesteps, hidden_units, dropout_rate):\n",
    "#         super(TGCN, self).__init__()\n",
    "        \n",
    "#         # Graph convolutional layers\n",
    "#         self.gcn1 = tfa.layers.GraphConvolution(units=hidden_units, activation=\"relu\")\n",
    "#         self.gcn2 = tfa.layers.GraphConvolution(units=hidden_units, activation=\"relu\")\n",
    "        \n",
    "#         # Temporal convolutional layers\n",
    "#         self.tcn1 = tf.keras.layers.Conv1D(filters=hidden_units, kernel_size=3, activation=\"relu\", padding=\"same\")\n",
    "#         self.tcn2 = tf.keras.layers.Conv1D(filters=hidden_units, kernel_size=3, activation=\"relu\", padding=\"same\")\n",
    "        \n",
    "#         # Output layer\n",
    "#         self.dense = tf.keras.layers.Dense(units=1, activation=None)\n",
    "        \n",
    "#         # Dropout layer\n",
    "#         self.dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n",
    "        \n",
    "#         # Reshape node features to 3D tensor\n",
    "#         self.reshape = tf.keras.layers.Reshape(target_shape=(num_timesteps, num_nodes, num_features))\n",
    "        \n",
    "#         # Transpose node features from (batch_size, num_timesteps, num_nodes, num_features) to \n",
    "#         # (batch_size, num_nodes, num_timesteps, num_features) to match adjacency matrix shape\n",
    "#         self.transpose = tf.keras.layers.Permute(dims=(1, 2, 0, 3))\n",
    "    \n",
    "#     def call(self, inputs, training=False):\n",
    "#         # Unpack input dictionary\n",
    "#         adj_matrix = inputs[\"adj_matrix\"]\n",
    "#         node_features = inputs[\"node_features\"]\n",
    "        \n",
    "#         # Reshape node features to 3D tensor\n",
    "#         node_features = self.reshape(node_features)\n",
    "        \n",
    "#         # Transpose node features to match adjacency matrix shape\n",
    "#         node_features = self.transpose(node_features)\n",
    "        \n",
    "#         # Apply graph convolutional layers\n",
    "#         h = self.gcn1([node_features, adj_matrix])\n",
    "#         h = self.dropout(h, training=training)\n",
    "#         h = self.gcn2([h, adj_matrix])\n",
    "#         h = self.dropout(h, training=training)\n",
    "        \n",
    "#         # Apply temporal convolutional layers\n",
    "#         h = self.tcn1(h)\n",
    "#         h = self.dropout(h, training=training)\n",
    "#         h = self.tcn2(h)\n",
    "#         h = self.dropout(h, training=training)\n",
    "        \n",
    "#         # Reshape output tensor to 2D tensor\n",
    "#         h = tf.keras.layers.Flatten()(h)\n",
    "        \n",
    "#         # Apply output layer\n",
    "#         outputs = self.dense(h)\n",
    "        \n",
    "#         return outputs\n",
    "\n",
    "# from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# class GCN:\n",
    "#     def __init__(self, filters, output_dim, activation, dropout):\n",
    "#         self.filters = filters\n",
    "#         self.output_dim = output_dim\n",
    "#         self.activation = activation\n",
    "#         self.dropout = dropout\n",
    "    \n",
    "#     def __call__(self, inputs):\n",
    "#         x, a = inputs\n",
    "        \n",
    "#         # Graph convolutional layer\n",
    "#         h = Dense(self.filters, activation=self.activation)(x)\n",
    "#         h = Dropout(self.dropout)(h)\n",
    "#         h = Dense(self.output_dim, activation=None)(h)\n",
    "        \n",
    "#         # Graph pooling layer\n",
    "#         pooled = Lambda(lambda x: tf.matmul(a, x))(h)\n",
    "        \n",
    "#         return self.activation(pooled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "# from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tcn import TCN\n",
    "\n",
    "# # Data dimensions\n",
    "# num_nodes = 17\n",
    "# num_features = 6\n",
    "# num_timesteps = 16\n",
    "\n",
    "# # Data\n",
    "# adj_matrix_data = np.random.randn(num_nodes, num_nodes, num_timesteps)\n",
    "# node_features_data = np.random.randn(num_nodes, num_timesteps, num_features)\n",
    "# target_data = np.random.randn(num_nodes, num_timesteps, 1)\n",
    "\n",
    "# train_data = {\"adj_matrix\": adj_matrix_data[:2], \"node_features\": node_features_data[:2]}\n",
    "# train_targets = target_data[:2]\n",
    "# test_data = {\"adj_matrix\": adj_matrix_data[2:], \"node_features\": node_features_data[2:]}\n",
    "# test_targets = target_data[2:]\n",
    "\n",
    "# # Model\n",
    "# num_filters = 16\n",
    "# kernel_size = 3\n",
    "# dropout_rate = 0.2\n",
    "\n",
    "# def get_model():\n",
    "#     inputs = []\n",
    "#     outputs = []\n",
    "#     for i in range(num_timesteps):\n",
    "#         adj_matrix_input = Input(shape=(num_nodes, num_nodes), name=f\"adj_matrix_{i}\")\n",
    "#         node_features_input = Input(shape=(num_nodes, num_features), name=f\"node_features_{i}\")\n",
    "#         gcn = tf.keras.layers.GCNConv(\n",
    "#             filters=num_filters,\n",
    "#             kernel_size=kernel_size,\n",
    "#             activation='relu'\n",
    "#         )(node_features_input, adj_matrix_input)\n",
    "#         gcn = Dropout(dropout_rate)(gcn)\n",
    "#         tcn = TCN(\n",
    "#             nb_filters=num_filters,\n",
    "#             kernel_size=kernel_size,\n",
    "#             dilations=[1, 2, 4, 8],\n",
    "#             dropout_rate=dropout_rate,\n",
    "#             use_skip_connections=True,\n",
    "#             activation='relu'\n",
    "#         )(gcn)\n",
    "#         tcn = Dropout(dropout_rate)(tcn)\n",
    "#         output = Dense(1, activation='linear')(tcn)\n",
    "#         inputs += [adj_matrix_input, node_features_input]\n",
    "#         outputs += [output]\n",
    "\n",
    "#     model = Model(inputs=inputs, outputs=outputs)\n",
    "#     model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "#     return model\n",
    "\n",
    "# model = get_model()\n",
    "# model.summary()\n",
    "\n",
    "# # Training\n",
    "# history = model.fit(\n",
    "#     x=[train_data[\"adj_matrix\"], train_data[\"node_features\"]],\n",
    "#     y=train_targets,\n",
    "#     epochs=10,\n",
    "#     batch_size=2,\n",
    "#     validation_data=([test_data[\"adj_matrix\"], test_data[\"node_features\"]], test_targets)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# num_nodes = 17\n",
    "# num_features = 6\n",
    "# num_timesteps = 16\n",
    "\n",
    "# # Define the T-GCN model architecture\n",
    "# class TGCN(tf.keras.Model):\n",
    "#     def _init_(self, num_nodes, num_features):\n",
    "#         super(TGCN, self)._init_()\n",
    "#         self.conv1 = tf.keras.layers.Convolutional1D(filters=32, kernel_size=2, activation='relu')\n",
    "#         self.conv2 = tf.keras.layers.Convolutional1D(filters=16, kernel_size=2, activation='relu')\n",
    "#         self.pool = tf.keras.layers.GlobalMaxPooling1D()\n",
    "#         self.dense1 = tf.keras.layers.Dense(units=64, activation='relu')\n",
    "#         self.dense2 = tf.keras.layers.Dense(units=1)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # Extract the adjacency matrix and node features from the input dictionary\n",
    "#         adj_matrix = inputs['adj_matrix']\n",
    "#         node_features = inputs['node_features']\n",
    "\n",
    "#         # Apply graph convolutional layers\n",
    "#         x = tf.transpose(node_features, perm=[0, 2, 1])\n",
    "#         for i in range(adj_matrix.shape[2]):\n",
    "#             x = tf.matmul(adj_matrix[:, :, i], x)\n",
    "#             x = self.conv1(x)\n",
    "#             x = self.conv2(x)\n",
    "#             x = self.pool(x)\n",
    "\n",
    "#         # Apply dense layers\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dense2(x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "# # Create an instance of the TGCN model\n",
    "# model = TGCN(num_nodes, num_features)\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "# # # Train the model\n",
    "# # model.fit(train_data, train_targets, epochs=10, batch_size=2)\n",
    "\n",
    "# # # Evaluate the model on the test data\n",
    "# # loss = model.evaluate(test_data, test_targets)\n",
    "# # print('Test loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from spektral.layers import GCNConv\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "# # Define the GCN model architecture\n",
    "# class GCN(tf.keras.Model):\n",
    "#     def __init__(self, num_nodes, num_features, num_filters):\n",
    "#         super(GCN, self).__init__()\n",
    "\n",
    "#         # Define the graph convolutional layer\n",
    "#         self.gcn_layer = GCNConv(num_filters, activation='relu')\n",
    "\n",
    "#         # Define the output layer\n",
    "#         self.output_layer = layers.Dense(1, activation=None)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         # Extract the input data\n",
    "#         adj_matrix = inputs['adj_matrix']\n",
    "#         node_features = inputs['node_features']\n",
    "\n",
    "#         # Apply the graph convolutional layer\n",
    "#         x = self.gcn_layer([node_features, adj_matrix])\n",
    "\n",
    "#         # Compute the output\n",
    "#         output = self.output_layer(x)\n",
    "#         return output\n",
    "\n",
    "# # Define the model hyperparameters\n",
    "# num_nodes = 17\n",
    "# num_features = 6\n",
    "# num_filters = 16\n",
    "\n",
    "# # Create an instance of the GCN model\n",
    "# model = GCN(num_nodes, num_features, num_filters)\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse', metrics=['mae'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Generate some sample data\n",
    "# adj_matrix_data = np.random.randn(num_nodes, num_timesteps, num_nodes)\n",
    "# node_features_data = np.random.randn(num_nodes, num_timesteps, num_features)\n",
    "# target_data = np.random.randn(num_nodes, num_timesteps, 1)\n",
    "\n",
    "# # Split the data into training and validation sets\n",
    "# train_data = {\"adj_matrix\": adj_matrix_data[2:], \"node_features\": node_features_data[2:]}\n",
    "# train_targets = target_data[2:]  # Keep only the first 15 timesteps\n",
    "# test_data = {\"adj_matrix\": adj_matrix_data[:2], \"node_features\": node_features_data[:2]}\n",
    "# test_targets = target_data[:2]  # Keep only the first 15 timesteps\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# model.fit(train_data, train_targets, epochs=10, validation_data=(test_data, test_targets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==========================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from spektral.layers import GCNConv\n",
    "\n",
    "# class GCN(tf.keras.Model):\n",
    "#     def __init__(self, num_features, num_timesteps):\n",
    "#         super(GCN, self).__init__()\n",
    "\n",
    "#         self.conv1 = GCNConv(64, activation=\"relu\")\n",
    "#         self.conv2 = GCNConv(32, activation=\"relu\")\n",
    "#         self.flatten = tf.keras.layers.Flatten()\n",
    "#         self.dense1 = tf.keras.layers.Dense(16, activation=\"relu\")\n",
    "#         self.dense2 = tf.keras.layers.Dense(1)\n",
    "\n",
    "#         self.adj_shape = (num_timesteps, None, None)\n",
    "#         self.features_shape = (num_timesteps, None, num_features)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         x, a = inputs[\"node_features\"], inputs[\"adj_matrix\"]\n",
    "#         a = tf.transpose(a, perm=[0, 2, 1])\n",
    "#         a = tf.linalg.matmul(a, tf.transpose(a, perm=[0, 2, 1]))\n",
    "#         x = self.conv1([x, a])\n",
    "#         x = self.conv2([x, a])\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dense2(x)\n",
    "\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_nodes = 17\n",
    "# num_features = 6\n",
    "# num_timesteps = 16\n",
    "\n",
    "# adj_matrix_data = np.random.randn(num_nodes, num_nodes, num_timesteps)\n",
    "# node_features_data = np.random.randn(num_nodes, num_timesteps, num_features)\n",
    "# target_data = np.random.randn(num_nodes, num_timesteps, 1)\n",
    "\n",
    "# train_data = {\"adj_matrix\": adj_matrix_data[:2], \"node_features\": node_features_data[:2]}\n",
    "# train_targets = target_data[:2]\n",
    "# test_data = {\"adj_matrix\": adj_matrix_data[2:], \"node_features\": node_features_data[2:]}\n",
    "# test_targets = target_data[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GCN(num_features=num_features, num_timesteps=num_timesteps)\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "# model.fit(train_data, train_targets, epochs=100, validation_data=(test_data, test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Data\n",
    "# adj_matrix_data = np.random.randn(num_nodes, num_nodes, num_timesteps)\n",
    "# node_features_data = np.random.randn(num_nodes, num_timesteps, num_features)\n",
    "# target_data = np.random.randn(num_nodes, num_timesteps, 1)\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# train_data = {\"adj_matrix\": adj_matrix_data[:2], \"node_features\": node_features_data[:2]}\n",
    "# train_targets = target_data[:2]\n",
    "# test_data = {\"adj_matrix\": adj_matrix_data[2:], \"node_features\": node_features_data[2:]}\n",
    "# test_targets = target_data[2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e6ccb18171910d5d756c184c3d0d59be6f710cbd132bfcf72abf48c375ba986"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
