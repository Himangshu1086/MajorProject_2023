{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorly as tl\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, GRU, Reshape, Concatenate, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route = pd.read_excel('route_data/U101.xlsx',index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_route_102 = pd.read_excel('route_data/U102.xlsx',index_col=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION FOR CNN HOURLY VARIATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def scale_data(arr):\n",
    "    # Reshape the array to a 2D matrix with shape (m*n, p)\n",
    "    reshaped_arr = arr.reshape((-1, arr.shape[-1]))\n",
    "    # Create a MinMaxScaler object and apply it to the reshaped array\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_arr = scaler.fit_transform(reshaped_arr)\n",
    "    # Reshape the scaled array back to the original shape\n",
    "    scaled_arr = scaled_arr.reshape(arr.shape)\n",
    "    return scaled_arr\n",
    "\n",
    "def data_prepare_cnn(df_route):\n",
    "    df_route = df_route[['ETD_DATE','Hour','ORIGIN','DESTINATION']]\n",
    "    df_route_unique = pd.DataFrame(df_route.value_counts())\n",
    "    df_route_unique = df_route_unique.reset_index()\n",
    "    df_route_unique.rename(columns={0:'TRAFFIC FLOW'},inplace=True)\n",
    "    land_use = pd.read_csv(\"Land_Use.csv\")\n",
    "    land_use.fillna(0,inplace=True)\n",
    "    # merged_data_final = pd.merge(df_route_unique, land_use, left_on='ORIGIN', right_on='STOPS')\n",
    "    # merged_data_final.drop(columns=['STOPS'],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    ten_graph_data = []\n",
    "    grp_hr = df_route_unique.groupby(['ETD_DATE','Hour'])\n",
    "    for i, df in grp_hr:\n",
    "        adj_matrix = np.zeros((51,51))\n",
    "        for index, row in df.iterrows():\n",
    "            adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] = adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] + int(row['TRAFFIC FLOW'])\n",
    "        ten_graph_data.append(tl.tensor(adj_matrix).reshape(51,51))\n",
    "    tensor_graph_data = tf.convert_to_tensor(ten_graph_data)\n",
    "    tensor_graph_data = np.array(tensor_graph_data)\n",
    "\n",
    "\n",
    "    unique_values = pd.unique(df_route_unique[['ORIGIN','DESTINATION']].values.ravel('K'))\n",
    "    land_use[land_use['STOPS'].isin(unique_values)==False][['COMMERCIAL','PUBLIC_and_SEMI_PUBLIC','INDUSTRIAL','RESIDENTIAL','PARKS','PUBLIC_UTILITIES']] = 0\n",
    "\n",
    "    pivot_table_for_node_features = np.array(land_use[['COMMERCIAL', 'PUBLIC_and_SEMI_PUBLIC', 'INDUSTRIAL', 'RESIDENTIAL','PARKS', 'PUBLIC_UTILITIES']])\n",
    "    list_node_features = []\n",
    "    for i in range(len(tensor_graph_data)):\n",
    "            list_node_features.append(pivot_table_for_node_features)\n",
    "    tensor_node_feature = tf.convert_to_tensor(list_node_features)\n",
    "    tensor_node_feature = np.array(tensor_node_feature)\n",
    "\n",
    "\n",
    "\n",
    "    ten_target_value = []\n",
    "    grp_date = df_route_unique.groupby(['ETD_DATE','Hour'])\n",
    "    for i, df in grp_date:\n",
    "        adj_matrix_target = np.zeros((51))\n",
    "        for index, row in df.iterrows():\n",
    "            adj_matrix_target[int(row['ORIGIN'])] = adj_matrix_target[int(row['ORIGIN'])] + int(row['TRAFFIC FLOW'])\n",
    "        ten_target_value.append(tl.tensor(adj_matrix_target))\n",
    "    tensor_target_value = tf.convert_to_tensor(ten_target_value)\n",
    "    tensor_target_value = np.array(tensor_target_value).reshape(len(tensor_graph_data),51,1)\n",
    "\n",
    "    # tensor_node_feature = scale_data(tensor_node_feature)\n",
    "    # tensor_graph_data = scale_data(tensor_graph_data)\n",
    "\n",
    "\n",
    "    return tensor_graph_data,tensor_node_feature,tensor_target_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_route = df_route[['ETD_DATE','ORIGIN','DESTINATION']]\n",
    "# df_route = pd.DataFrame(df_route.value_counts())\n",
    "# merged_data_final = df_route.reset_index()\n",
    "# merged_data_final.rename(columns={0:'TRAFFIC FLOW'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ten_graph_data = []\n",
    "# grp_hr = merged_data_final.groupby(['ETD_DATE'])\n",
    "# for i, df in grp_hr:\n",
    "#     adj_matrix = np.zeros((51,51))\n",
    "#     for index, row in df.iterrows():\n",
    "#         adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] = adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] + int(row['TRAFFIC FLOW'])\n",
    "#     ten_graph_data.append(tl.tensor(adj_matrix).reshape(51,51))\n",
    "# tensor_graph_data = tf.convert_to_tensor(ten_graph_data)\n",
    "# tensor_graph_data = np.array(tensor_graph_data)\n",
    "# tensor_graph_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ten_target_value = []\n",
    "# grp_date = merged_data_final.groupby(['ETD_DATE'])\n",
    "# for i, df in grp_date:\n",
    "#     adj_matrix_target = np.zeros((51))\n",
    "#     for index, row in df.iterrows():\n",
    "#         adj_matrix_target[int(row['ORIGIN'])] = adj_matrix_target[int(row['ORIGIN'])] + row['TRAFFIC FLOW']\n",
    "#     ten_target_value.append(tl.tensor(adj_matrix_target))\n",
    "# tensor_target_value = tf.convert_to_tensor(ten_target_value)\n",
    "# tensor_target_value = np.array(tensor_target_value).reshape(183,51,1)\n",
    "# tensor_target_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import numpy as np\n",
    "\n",
    "# def scale_data(arr):\n",
    "#     # Reshape the array to a 2D matrix with shape (m*n, p)\n",
    "#     reshaped_arr = arr.reshape((-1, arr.shape[-1]))\n",
    "#     # Create a MinMaxScaler object and apply it to the reshaped array\n",
    "#     scaler = MinMaxScaler()\n",
    "#     scaled_arr = scaler.fit_transform(reshaped_arr)\n",
    "#     # Reshape the scaled array back to the original shape\n",
    "#     scaled_arr = scaled_arr.reshape(arr.shape)\n",
    "#     return scaled_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANGSHUB\\AppData\\Local\\Temp\\ipykernel_8248\\3120778653.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  land_use[land_use['STOPS'].isin(unique_values)==False][['COMMERCIAL','PUBLIC_and_SEMI_PUBLIC','INDUSTRIAL','RESIDENTIAL','PARKS','PUBLIC_UTILITIES']] = 0\n"
     ]
    }
   ],
   "source": [
    "tensor_graph_data_scaled,nf,tensor_target_value = data_prepare_cnn(df_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 51\n",
    "num_features = 6\n",
    "num_timesteps = 2688\n",
    "train_data = tensor_graph_data_scaled[:2151]\n",
    "train_targets = tensor_target_value[1:2152].astype(np.int64)\n",
    "test_data = tensor_graph_data_scaled[2151:2687]\n",
    "test_targets = tensor_target_value[2152:].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN without the node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "68/68 [==============================] - 7s 88ms/step - loss: 4.2590 - val_loss: 3.5212\n",
      "Epoch 2/50\n",
      "68/68 [==============================] - 5s 74ms/step - loss: 3.0867 - val_loss: 2.8922\n",
      "Epoch 3/50\n",
      "68/68 [==============================] - 5s 76ms/step - loss: 2.5289 - val_loss: 2.5151\n",
      "Epoch 4/50\n",
      "68/68 [==============================] - 5s 77ms/step - loss: 2.1790 - val_loss: 2.2631\n",
      "Epoch 5/50\n",
      "68/68 [==============================] - 5s 77ms/step - loss: 2.0246 - val_loss: 2.1823\n",
      "Epoch 6/50\n",
      "68/68 [==============================] - 5s 71ms/step - loss: 1.9553 - val_loss: 2.1215\n",
      "Epoch 7/50\n",
      "68/68 [==============================] - 5s 70ms/step - loss: 1.9093 - val_loss: 2.0772\n",
      "Epoch 8/50\n",
      "68/68 [==============================] - 6s 82ms/step - loss: 1.8744 - val_loss: 2.0538\n",
      "Epoch 9/50\n",
      "68/68 [==============================] - 5s 75ms/step - loss: 1.8504 - val_loss: 2.0327\n",
      "Epoch 10/50\n",
      "68/68 [==============================] - 5s 73ms/step - loss: 1.8256 - val_loss: 2.0060\n",
      "Epoch 11/50\n",
      "68/68 [==============================] - 5s 74ms/step - loss: 1.8037 - val_loss: 1.9857\n",
      "Epoch 12/50\n",
      "68/68 [==============================] - 5s 73ms/step - loss: 1.7903 - val_loss: 1.9886\n",
      "Epoch 13/50\n",
      "68/68 [==============================] - 6s 84ms/step - loss: 1.7792 - val_loss: 1.9529\n",
      "Epoch 14/50\n",
      "68/68 [==============================] - 5s 79ms/step - loss: 1.7599 - val_loss: 1.9525\n",
      "Epoch 15/50\n",
      "68/68 [==============================] - 5s 80ms/step - loss: 1.7514 - val_loss: 1.9435\n",
      "Epoch 16/50\n",
      "68/68 [==============================] - 6s 85ms/step - loss: 1.7450 - val_loss: 1.9331\n",
      "Epoch 17/50\n",
      "68/68 [==============================] - 6s 83ms/step - loss: 1.7317 - val_loss: 1.9244\n",
      "Epoch 18/50\n",
      "68/68 [==============================] - 6s 93ms/step - loss: 1.7267 - val_loss: 1.9191\n",
      "Epoch 19/50\n",
      "68/68 [==============================] - 6s 90ms/step - loss: 1.7138 - val_loss: 1.9196\n",
      "Epoch 20/50\n",
      "68/68 [==============================] - 6s 89ms/step - loss: 1.7078 - val_loss: 1.9041\n",
      "Epoch 21/50\n",
      "68/68 [==============================] - 8s 114ms/step - loss: 1.7019 - val_loss: 1.9033\n",
      "Epoch 22/50\n",
      "68/68 [==============================] - 7s 98ms/step - loss: 1.6974 - val_loss: 1.9144\n",
      "Epoch 23/50\n",
      "68/68 [==============================] - 7s 105ms/step - loss: 1.6899 - val_loss: 1.9023\n",
      "Epoch 24/50\n",
      "68/68 [==============================] - 7s 101ms/step - loss: 1.6876 - val_loss: 1.8947\n",
      "Epoch 25/50\n",
      "68/68 [==============================] - 7s 102ms/step - loss: 1.6781 - val_loss: 1.8988\n",
      "Epoch 26/50\n",
      "68/68 [==============================] - 7s 98ms/step - loss: 1.6782 - val_loss: 1.8979\n",
      "Epoch 27/50\n",
      "68/68 [==============================] - 7s 97ms/step - loss: 1.6726 - val_loss: 1.8955\n",
      "Epoch 28/50\n",
      "68/68 [==============================] - 6s 86ms/step - loss: 1.6664 - val_loss: 1.9040\n",
      "Epoch 29/50\n",
      "68/68 [==============================] - 6s 92ms/step - loss: 1.6699 - val_loss: 1.9020\n",
      "Epoch 30/50\n",
      "68/68 [==============================] - 7s 98ms/step - loss: 1.6581 - val_loss: 1.8992\n",
      "Epoch 31/50\n",
      "68/68 [==============================] - 6s 92ms/step - loss: 1.6580 - val_loss: 1.8979\n",
      "Epoch 32/50\n",
      "68/68 [==============================] - 6s 88ms/step - loss: 1.6528 - val_loss: 1.8983\n",
      "Epoch 33/50\n",
      "68/68 [==============================] - 6s 87ms/step - loss: 1.6469 - val_loss: 1.8957\n",
      "Epoch 34/50\n",
      "68/68 [==============================] - 6s 90ms/step - loss: 1.6487 - val_loss: 1.8944\n",
      "Epoch 35/50\n",
      "68/68 [==============================] - 6s 92ms/step - loss: 1.6431 - val_loss: 1.8941\n",
      "Epoch 36/50\n",
      "68/68 [==============================] - 6s 89ms/step - loss: 1.6452 - val_loss: 1.8942\n",
      "Epoch 37/50\n",
      "68/68 [==============================] - 6s 87ms/step - loss: 1.6392 - val_loss: 1.8921\n",
      "Epoch 38/50\n",
      "68/68 [==============================] - 6s 88ms/step - loss: 1.6336 - val_loss: 1.8944\n",
      "Epoch 39/50\n",
      "68/68 [==============================] - 6s 89ms/step - loss: 1.6358 - val_loss: 1.8912\n",
      "Epoch 40/50\n",
      "68/68 [==============================] - 6s 84ms/step - loss: 1.6288 - val_loss: 1.9006\n",
      "Epoch 41/50\n",
      "68/68 [==============================] - 6s 87ms/step - loss: 1.6259 - val_loss: 1.8956\n",
      "Epoch 42/50\n",
      "68/68 [==============================] - 6s 87ms/step - loss: 1.6231 - val_loss: 1.8951\n",
      "Epoch 43/50\n",
      "68/68 [==============================] - 6s 86ms/step - loss: 1.6258 - val_loss: 1.8887\n",
      "Epoch 44/50\n",
      "68/68 [==============================] - 6s 91ms/step - loss: 1.6238 - val_loss: 1.8906\n",
      "Epoch 45/50\n",
      "68/68 [==============================] - 6s 88ms/step - loss: 1.6208 - val_loss: 1.9019\n",
      "Epoch 46/50\n",
      "68/68 [==============================] - 6s 84ms/step - loss: 1.6190 - val_loss: 1.8988\n",
      "Epoch 47/50\n",
      "68/68 [==============================] - 6s 85ms/step - loss: 1.6203 - val_loss: 1.9017\n",
      "Epoch 48/50\n",
      "68/68 [==============================] - 6s 91ms/step - loss: 1.6224 - val_loss: 1.8925\n",
      "Epoch 49/50\n",
      "68/68 [==============================] - 6s 92ms/step - loss: 1.6134 - val_loss: 1.8914\n",
      "Epoch 50/50\n",
      "68/68 [==============================] - 6s 83ms/step - loss: 1.6093 - val_loss: 1.8984\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\computer science\\REPOSITORY\\major_project\\MajorProject\\Traffic_flow_pred.ipynb Cell 18\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/computer%20science/REPOSITORY/major_project/MajorProject/Traffic_flow_pred.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(train_loss) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/computer%20science/REPOSITORY/major_project/MajorProject/Traffic_flow_pred.ipynb#X13sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# Plot training and validation loss\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/computer%20science/REPOSITORY/major_project/MajorProject/Traffic_flow_pred.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/computer%20science/REPOSITORY/major_project/MajorProject/Traffic_flow_pred.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m sns\u001b[39m.\u001b[39mlineplot(train_loss, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining Loss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/computer%20science/REPOSITORY/major_project/MajorProject/Traffic_flow_pred.ipynb#X13sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m sns\u001b[39m.\u001b[39mlineplot(val_loss, label\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValidation Loss\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(51, 51, 1)),\n",
    "    # layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    # layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
    "    # layers.MaxPooling2D(pool_size=(2,2)),\n",
    "    layers.Flatten(),\n",
    "    # layers.Dense(256, activation='relu'),\n",
    "    # layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(51, activation='linear')\n",
    "])\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "# Train the model\n",
    "history = model.fit(train_data, train_targets, epochs=50, batch_size=32, validation_data=(test_data, test_targets))\n",
    "# Get training and validation loss from the history object\n",
    "# train_loss = history.history[\"loss\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "# # Create a list of epoch numbers\n",
    "# epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# # Plot training and validation loss\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.lineplot(train_loss, label=\"Training Loss\")\n",
    "# sns.lineplot(val_loss, label=\"Validation Loss\")\n",
    "# plt.title(\"Training and Validation Loss\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_data).astype(np.int64)\n",
    "test_targets = test_targets.reshape(536,51).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  0.23489998849080265\n",
      "MAE :  1.859452736318408\n",
      "MSE :  31.955004389815624\n",
      "RMSE :  5.6528757628145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error , mean_absolute_error , mean_squared_error\n",
    "import math\n",
    "print(\"MAPE : \" ,mean_absolute_percentage_error(train_targets.reshape(2151,51)[:10],predictions[:10]))\n",
    "print(\"MAE : \" ,mean_absolute_error(test_targets,predictions))\n",
    "print(\"MSE : \" ,mean_squared_error(test_targets,predictions))\n",
    "print(\"RMSE : \", math.sqrt(mean_squared_error(test_targets,predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION FOR LSTM AND ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare_hr(input_data):\n",
    "    input_data = input_data[['ETD_DATE','ORIGIN','DESTINATION']]\n",
    "    df_route_unique = pd.DataFrame(input_data.value_counts())\n",
    "    df_route_unique = df_route_unique.reset_index()\n",
    "    df_route_unique.rename(columns={0:'TRAFFIC FLOW'},inplace=True)\n",
    "\n",
    "    ten_graph_data = []\n",
    "    grp_hr = df_route_unique.groupby(['ETD_DATE'])\n",
    "    for i, df in grp_hr:\n",
    "        adj_matrix = np.zeros((51,51))\n",
    "        for index, row in df.iterrows():\n",
    "            adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] = adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] + int(row['TRAFFIC FLOW'])\n",
    "        ten_graph_data.append(tl.tensor(adj_matrix).reshape(51,51))\n",
    "    tensor_graph_data = tf.convert_to_tensor(ten_graph_data)\n",
    "    tensor_graph_data = np.array(tensor_graph_data)\n",
    "    return tensor_graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANGSHUB\\AppData\\Local\\Temp\\ipykernel_8248\\3156511175.py:9: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for i, df in grp_hr:\n"
     ]
    }
   ],
   "source": [
    "tensor_graph_data = data_prepare_hr(df_route)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM without node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 4s 150ms/step - loss: 2.0017 - val_loss: 2.1605\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.9722 - val_loss: 2.1243\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.9339 - val_loss: 2.0831\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.8911 - val_loss: 2.0366\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.8455 - val_loss: 1.9903\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.8021 - val_loss: 1.9490\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.7631 - val_loss: 1.9122\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.7267 - val_loss: 1.8764\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.6930 - val_loss: 1.8483\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.6666 - val_loss: 1.8232\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.6435 - val_loss: 1.8020\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.6245 - val_loss: 1.7852\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.6095 - val_loss: 1.7713\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5972 - val_loss: 1.7598\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5864 - val_loss: 1.7497\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.5776 - val_loss: 1.7422\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1.5709 - val_loss: 1.7362\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.5655 - val_loss: 1.7312\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.5611 - val_loss: 1.7271\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.5574 - val_loss: 1.7237\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.5543 - val_loss: 1.7208\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5516 - val_loss: 1.7183\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5492 - val_loss: 1.7162\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.5472 - val_loss: 1.7144\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5453 - val_loss: 1.7127\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5437 - val_loss: 1.7112\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.5422 - val_loss: 1.7099\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5409 - val_loss: 1.7088\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5396 - val_loss: 1.7078\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5384 - val_loss: 1.7068\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5374 - val_loss: 1.7060\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5363 - val_loss: 1.7052\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5354 - val_loss: 1.7045\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5345 - val_loss: 1.7039\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5336 - val_loss: 1.7033\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5328 - val_loss: 1.7028\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5320 - val_loss: 1.7023\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.5312 - val_loss: 1.7018\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5305 - val_loss: 1.7013\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5297 - val_loss: 1.7008\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5290 - val_loss: 1.7004\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5283 - val_loss: 1.6999\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5276 - val_loss: 1.6995\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.5270 - val_loss: 1.6990\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5263 - val_loss: 1.6986\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5258 - val_loss: 1.6983\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5253 - val_loss: 1.6979\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5248 - val_loss: 1.6975\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5243 - val_loss: 1.6971\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5238 - val_loss: 1.6968\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Define window size for input/output pairs\n",
    "window_size = 3\n",
    "\n",
    "# Create input/output pairs\n",
    "X = []\n",
    "y = []\n",
    "for i in range(len(tensor_graph_data) - window_size):\n",
    "    X.append(tensor_graph_data[i:i+window_size])\n",
    "    y.append(tensor_graph_data[i+window_size])\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Reshape input data to have correct number of dimensions\n",
    "X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]*X.shape[3])).astype(np.int64)\n",
    "y = np.reshape(y,(y.shape[0], y.shape[1]*y.shape[2])).astype(np.int64)\n",
    "# Define LSTM model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(window_size,51*51)))\n",
    "# model.add(Dropout(0.3))\n",
    "# model.add(LSTM(64))\n",
    "# model.add(Dropout(0.3))\n",
    "model.add(Dense(51*51, activation='sigmoid'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),loss='mae')\n",
    "\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# # Get training and validation loss from the history object\n",
    "# train_loss = history.history[\"loss\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "# # Create a list of epoch numbers\n",
    "# epochs = range(1, len(train_loss) + 1)\n",
    "# # Plot training and validation loss\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.lineplot(train_loss, label=\"Training Loss\")\n",
    "# sns.lineplot(val_loss, label=\"Validation Loss\")\n",
    "# plt.title(\"Training and Validation Loss\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  0.05088213934811397\n",
      "MAE :  1.594649493784442\n",
      "MSE :  165.012433252168\n",
      "RMSE :  12.845716533232702\n"
     ]
    }
   ],
   "source": [
    "prediction_lstm = model.predict(X).astype(np.int64)\n",
    "# mapeTensor = tf.keras.losses.mape(prediction,y[:9].astype(np.float64))\n",
    "# np.mean(mapeTensor.numpy())\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error , mean_absolute_error , mean_squared_error\n",
    "import math\n",
    "print(\"MAPE : \" ,mean_absolute_percentage_error(y,prediction_lstm))\n",
    "print(\"MAE : \" ,mean_absolute_error(y,prediction_lstm))\n",
    "print(\"MSE : \" ,mean_squared_error(y,prediction_lstm))\n",
    "print(\"RMSE : \", math.sqrt(mean_squared_error(y,prediction_lstm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN model without node features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 1s 110ms/step - loss: 1.6467 - val_loss: 1.6870\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 0s 66ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 1.5235 - val_loss: 1.6869\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.5235 - val_loss: 1.6869\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(3, 51*51)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # tf.keras.layers.Dense(128, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(51*51, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model with appropriate loss function, optimizer and metric\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),loss='mae')\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X, y, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# # Get training and validation loss from the history object\n",
    "# train_loss = history.history[\"loss\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "# # Create a list of epoch numbers\n",
    "# epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# # Plot training and validation loss\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.lineplot(train_loss, label=\"Training Loss\")\n",
    "# sns.lineplot(val_loss, label=\"Validation Loss\")\n",
    "# plt.title(\"Training and Validation Loss\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  45634321483714.91\n",
      "MAE :  1.556157887991798\n",
      "MSE :  162.04808834209067\n",
      "RMSE :  12.729811009676878\n"
     ]
    }
   ],
   "source": [
    "prediction_ann = model.predict(X).astype(np.int64)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error , mean_absolute_error , mean_squared_error\n",
    "import math\n",
    "print(\"MAPE : \" ,mean_absolute_percentage_error(y,prediction_ann))\n",
    "print(\"MAE : \" ,mean_absolute_error(y,prediction_ann))\n",
    "print(\"MSE : \" ,mean_squared_error(y,prediction_ann))\n",
    "print(\"RMSE : \", math.sqrt(mean_squared_error(y,prediction_ann)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING WITH OTHER ROUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HIMANGSHUB\\AppData\\Local\\Temp\\ipykernel_8248\\3156511175.py:9: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for i, df in grp_hr:\n"
     ]
    }
   ],
   "source": [
    "testing = data_prepare_hr(df_route_102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3\n",
    "\n",
    "# Create input/output pairs\n",
    "X_t = []\n",
    "y_t = []\n",
    "for i in range(len(testing) - window_size):\n",
    "    X_t.append(testing[i:i+window_size])\n",
    "    y_t.append(testing[i+window_size])\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_t = np.array(X_t)\n",
    "y_t = np.array(y_t)\n",
    "\n",
    "# Reshape input data to have correct number of dimensions\n",
    "X_t = np.reshape(X_t, (X_t.shape[0], X_t.shape[1], X_t.shape[2]*X_t.shape[3])).astype(np.int64)\n",
    "y_t = np.reshape(y_t,(y_t.shape[0], y_t.shape[1]*y_t.shape[2])).astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE :  228902680022445.06\n",
      "MAE :  1.5801038062283739\n",
      "MSE :  155.5891131616045\n",
      "RMSE :  12.473536513820148\n"
     ]
    }
   ],
   "source": [
    "prediction_ann_test = model.predict(X_t).astype(np.int64)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_percentage_error , mean_absolute_error , mean_squared_error\n",
    "import math\n",
    "print(\"MAPE : \" ,mean_absolute_percentage_error(y_t[:5],prediction_ann_test[:5]))\n",
    "print(\"MAE : \" ,mean_absolute_error(y_t,prediction_ann_test))\n",
    "print(\"MSE : \" ,mean_squared_error(y_t,prediction_ann_test))\n",
    "print(\"RMSE : \", math.sqrt(mean_squared_error(y_t,prediction_ann_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL NETWORK PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = pd.read_excel(\"route_data/U101.xlsx\",index_col=False)\n",
    "df1 = pd.read_excel('route_data/U102.xlsx',index_col=False)\n",
    "df2 = pd.read_excel('route_data/U105.xlsx',index_col=False)\n",
    "df3 = pd.read_excel('route_data/U106.xlsx',index_col=False)\n",
    "df4 = pd.read_excel('route_data/U107.xlsx',index_col=False)\n",
    "df5 = pd.read_excel('route_data/U108.xlsx',index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_network = pd.concat([df0,df1,df2,df3,df4,df5],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare(input_data):\n",
    "    input_data = input_data[['ETD_DATE','ORIGIN','DESTINATION']]\n",
    "    df_route_unique = pd.DataFrame(input_data.value_counts())\n",
    "    df_route_unique = df_route_unique.reset_index()\n",
    "    df_route_unique.rename(columns={0:'TRAFFIC FLOW'},inplace=True)\n",
    "\n",
    "    ten_graph_data = []\n",
    "    grp_hr = df_route_unique.groupby(['ETD_DATE'])\n",
    "    for i, df in grp_hr:\n",
    "        adj_matrix = np.zeros((51,51))\n",
    "        for index, row in df.iterrows():\n",
    "            adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] = adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] + int(row['TRAFFIC FLOW'])\n",
    "        ten_graph_data.append(tl.tensor(adj_matrix).reshape(51,51))\n",
    "    tensor_graph_data = tf.convert_to_tensor(ten_graph_data)\n",
    "    tensor_graph_data = np.array(tensor_graph_data)\n",
    "\n",
    "    # tensor_node_feature = scale_data(tensor_node_feature)\n",
    "    # tensor_graph_data = scale_data(tensor_graph_data)\n",
    "\n",
    "\n",
    "    return tensor_graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare_hr(input_data):\n",
    "    input_data = input_data[['ETD_DATE','Hour','ORIGIN','DESTINATION']]\n",
    "    df_route_unique = pd.DataFrame(input_data.value_counts())\n",
    "    df_route_unique = df_route_unique.reset_index()\n",
    "    df_route_unique.rename(columns={0:'TRAFFIC FLOW'},inplace=True)\n",
    "\n",
    "    ten_graph_data = []\n",
    "    grp_hr = df_route_unique.groupby(['ETD_DATE','Hour'])\n",
    "    for i, df in grp_hr:\n",
    "        adj_matrix = np.zeros((51,51))\n",
    "        for index, row in df.iterrows():\n",
    "            adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] = adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] + int(row['TRAFFIC FLOW'])\n",
    "        ten_graph_data.append(tl.tensor(adj_matrix).reshape(51,51))\n",
    "    tensor_graph_data = tf.convert_to_tensor(ten_graph_data)\n",
    "    tensor_graph_data = np.array(tensor_graph_data)\n",
    "\n",
    "    # tensor_node_feature = scale_data(tensor_node_feature)\n",
    "    # tensor_graph_data = scale_data(tensor_graph_data)\n",
    "\n",
    "\n",
    "    return tensor_graph_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = data_prepare_hr(full_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - 13s 80ms/step - loss: 0.5349 - val_loss: 0.4825\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.3910 - val_loss: 0.3529\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 4s 62ms/step - loss: 0.3383 - val_loss: 0.3172\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.3241 - val_loss: 0.3121\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 3s 54ms/step - loss: 0.3178 - val_loss: 0.3082\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 0.3144 - val_loss: 0.3046\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.3096 - val_loss: 0.3042\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 0.3078 - val_loss: 0.3000\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.3050 - val_loss: 0.3028\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.3059 - val_loss: 0.3032\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.2991 - val_loss: 0.2987\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 0.2949 - val_loss: 0.2981\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2926 - val_loss: 0.2954\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.2902 - val_loss: 0.2984\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.2893 - val_loss: 0.3015\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2880 - val_loss: 0.2976\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.2877 - val_loss: 0.2975\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 0.2879 - val_loss: 0.2982\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.2854 - val_loss: 0.2961\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2841 - val_loss: 0.2932\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.2821 - val_loss: 0.2938\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 3s 54ms/step - loss: 0.2823 - val_loss: 0.2954\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.2820 - val_loss: 0.2934\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.2823 - val_loss: 0.2956\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2809 - val_loss: 0.2978\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2809 - val_loss: 0.2910\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2795 - val_loss: 0.2999\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 0.2822 - val_loss: 0.2918\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 0.2792 - val_loss: 0.2911\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.2792 - val_loss: 0.2924\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2784 - val_loss: 0.2936\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.2811 - val_loss: 0.2909\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2778 - val_loss: 0.2911\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.2777 - val_loss: 0.2924\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 0.2774 - val_loss: 0.2903\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.2765 - val_loss: 0.2924\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2768 - val_loss: 0.2917\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2766 - val_loss: 0.2926\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2762 - val_loss: 0.2909\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 0.2760 - val_loss: 0.2924\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2762 - val_loss: 0.2906\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2760 - val_loss: 0.2911\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 3s 55ms/step - loss: 0.2745 - val_loss: 0.2909\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 3s 54ms/step - loss: 0.2752 - val_loss: 0.2921\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.2747 - val_loss: 0.2915\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 3s 54ms/step - loss: 0.2748 - val_loss: 0.2941\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2754 - val_loss: 0.2936\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2768 - val_loss: 0.2942\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2755 - val_loss: 0.2954\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.2745 - val_loss: 0.2951\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2754 - val_loss: 0.2948\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2743 - val_loss: 0.2943\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 0.2737 - val_loss: 0.2922\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2738 - val_loss: 0.2941\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2747 - val_loss: 0.2931\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 0.2734 - val_loss: 0.2928\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2724 - val_loss: 0.2941\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2727 - val_loss: 0.2918\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2730 - val_loss: 0.2928\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2736 - val_loss: 0.2928\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.2738 - val_loss: 0.2929\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2732 - val_loss: 0.2927\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 0.2721 - val_loss: 0.2940\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2722 - val_loss: 0.2951\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 0.2714 - val_loss: 0.2920\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.2714 - val_loss: 0.2915\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2708 - val_loss: 0.2917\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.2714 - val_loss: 0.2909\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.2711 - val_loss: 0.2931\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 0.2709 - val_loss: 0.2921\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 3s 54ms/step - loss: 0.2708 - val_loss: 0.2917\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.2700 - val_loss: 0.2915\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 3s 56ms/step - loss: 0.2701 - val_loss: 0.2924\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 0.2712 - val_loss: 0.2912\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2713 - val_loss: 0.2922\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 3s 53ms/step - loss: 0.2708 - val_loss: 0.2923\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2733 - val_loss: 0.2914\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 3s 48ms/step - loss: 0.2714 - val_loss: 0.2918\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2708 - val_loss: 0.2910\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 3s 54ms/step - loss: 0.2707 - val_loss: 0.2943\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2706 - val_loss: 0.2934\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2698 - val_loss: 0.2905\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.2689 - val_loss: 0.2921\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2692 - val_loss: 0.2929\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2731 - val_loss: 0.2921\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.2697 - val_loss: 0.2912\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.2698 - val_loss: 0.2902\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2693 - val_loss: 0.2917\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2704 - val_loss: 0.2899\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2709 - val_loss: 0.2913\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2699 - val_loss: 0.2903\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2685 - val_loss: 0.2922\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 3s 51ms/step - loss: 0.2694 - val_loss: 0.2902\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2689 - val_loss: 0.2921\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2699 - val_loss: 0.2929\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2705 - val_loss: 0.2939\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2699 - val_loss: 0.2924\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 3s 52ms/step - loss: 0.2689 - val_loss: 0.2936\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 3s 49ms/step - loss: 0.2686 - val_loss: 0.2906\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 3s 50ms/step - loss: 0.2684 - val_loss: 0.2916\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "window_size = 7\n",
    "X_full = []\n",
    "y_full = []\n",
    "for i in range(len(input_tensor) - window_size):\n",
    "    X_full.append(input_tensor[i:i+window_size])\n",
    "    y_full.append(input_tensor[i+window_size])\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_full = np.array(X_full)\n",
    "y_full = np.array(y_full)\n",
    "\n",
    "# Reshape input data to have correct number of dimensions\n",
    "X_full = np.reshape(X_full, (X_full.shape[0], X_full.shape[1], X_full.shape[2]*X_full.shape[3]))\n",
    "y_full = np.reshape(y_full,(y_full.shape[0], y_full.shape[1]*y_full.shape[2]))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(window_size,51*51), return_sequences=True ))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(51*51, activation='linear'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),loss='mae')\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_full, y_full, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Get training and validation loss from the history object\n",
    "train_loss = history.history[\"loss\"]\n",
    "val_loss = history.history[\"val_loss\"]\n",
    "# Create a list of epoch numbers\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(train_loss, label=\"Training Loss\")\n",
    "sns.lineplot(val_loss, label=\"Validation Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = model.predict(X_full[:150]).astype(np.int64)\n",
    "# mapeTensor = tf.keras.losses.mean_absolute_error(y_full[:150],prediction)\n",
    "# np.mean(mapeTensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def scale_data(arr):\n",
    "    # Reshape the array to a 2D matrix with shape (m*n, p)\n",
    "    reshaped_arr = arr.reshape((-1, arr.shape[-1]))\n",
    "    # Create a MinMaxScaler object and apply it to the reshaped array\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_arr = scaler.fit_transform(reshaped_arr)\n",
    "    # Reshape the scaled array back to the original shape\n",
    "    scaled_arr = scaled_arr.reshape(arr.shape)\n",
    "    return scaled_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepare_temp(df_route):\n",
    "    df_route = df_route[['ETD_DATE','Hour','ORIGIN','DESTINATION']]\n",
    "    df_route_unique = pd.DataFrame(df_route.value_counts())\n",
    "    df_route_unique = df_route_unique.reset_index()\n",
    "    df_route_unique.rename(columns={0:'TRAFFIC FLOW'},inplace=True)\n",
    "    land_use = pd.read_csv(\"Land_Use.csv\")\n",
    "    land_use.fillna(0,inplace=True)\n",
    "    # merged_data_final = pd.merge(df_route_unique, land_use, left_on='ORIGIN', right_on='STOPS')\n",
    "    # merged_data_final.drop(columns=['STOPS'],inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    ten_graph_data = []\n",
    "    grp_hr = df_route_unique.groupby(['ETD_DATE','Hour'])\n",
    "    for i, df in grp_hr:\n",
    "        adj_matrix = np.zeros((51,51))\n",
    "        for index, row in df.iterrows():\n",
    "            adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] = adj_matrix[int(row['ORIGIN'])][int(row['DESTINATION'])] + int(row['TRAFFIC FLOW'])\n",
    "        ten_graph_data.append(tl.tensor(adj_matrix).reshape(51,51))\n",
    "    tensor_graph_data = tf.convert_to_tensor(ten_graph_data)\n",
    "    tensor_graph_data = np.array(tensor_graph_data)\n",
    "\n",
    "\n",
    "    # unique_values = pd.unique(merged_data_final[['ORIGIN','DESTINATION']].values.ravel('K'))\n",
    "    # land_use[land_use['STOPS'].isin(unique_values)==False][['COMMERCIAL','PUBLIC_and_SEMI_PUBLIC','INDUSTRIAL','RESIDENTIAL','PARKS','PUBLIC_UTILITIES']] = 0\n",
    "\n",
    "    pivot_table_for_node_features = np.array(land_use[['COMMERCIAL', 'PUBLIC_and_SEMI_PUBLIC', 'INDUSTRIAL', 'RESIDENTIAL','PARKS', 'PUBLIC_UTILITIES']])\n",
    "    list_node_features = []\n",
    "    for i in range(len(tensor_graph_data)):\n",
    "            list_node_features.append(pivot_table_for_node_features)\n",
    "    tensor_node_feature = tf.convert_to_tensor(list_node_features)\n",
    "    tensor_node_feature = np.array(tensor_node_feature)\n",
    "\n",
    "\n",
    "\n",
    "    ten_target_value = []\n",
    "    grp_date = df_route_unique.groupby(['ETD_DATE','Hour'])\n",
    "    for i, df in grp_date:\n",
    "        adj_matrix_target = np.zeros((51))\n",
    "        for index, row in df.iterrows():\n",
    "            adj_matrix_target[int(row['ORIGIN'])] = adj_matrix_target[int(row['ORIGIN'])] + row['TRAFFIC FLOW']\n",
    "        ten_target_value.append(tl.tensor(adj_matrix_target))\n",
    "    tensor_target_value = tf.convert_to_tensor(ten_target_value)\n",
    "    tensor_target_value = np.array(tensor_target_value).reshape(len(tensor_graph_data),51,1)\n",
    "\n",
    "    tensor_node_feature = scale_data(tensor_node_feature)\n",
    "    tensor_graph_data = scale_data(tensor_graph_data)\n",
    "\n",
    "\n",
    "    return tensor_graph_data,tensor_node_feature,tensor_target_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_graph_data_t,tensor_node_feature_t,tensor_target_value_t = data_prepare_temp(full_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor_graph_data_t.shape,tensor_node_feature_t.shape,tensor_target_value_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_nodes = 51\n",
    "# num_features = 6\n",
    "# num_timesteps = 2714\n",
    "# train_data = {\"adj_matrix\": tensor_graph_data_t[:2172], \"node_features\": tensor_node_feature_t[:2172]}\n",
    "# train_targets = tensor_target_value_t[1:2173].astype(np.int64)\n",
    "# test_data = {\"adj_matrix\": tensor_graph_data_t[2172:2713], \"node_features\": tensor_node_feature_t[2172:2713]}\n",
    "# test_targets = tensor_target_value_t[2173:].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from spektral.layers import GCNConv\n",
    "# from sklearn.ensemble import BaggingRegressor\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "# class GCN(tf.keras.Model):\n",
    "#     def __init__(self, num_features, num_timesteps,num_nodes):\n",
    "#         super(GCN, self).__init__()\n",
    "\n",
    "#         self.conv1 = GCNConv(256 ,activation=\"relu\")\n",
    "#         self.conv2 = GCNConv(128, activation=\"relu\")\n",
    "#         self.flatten = tf.keras.layers.Flatten()\n",
    "#         self.dense1 = tf.keras.layers.Dense(256, activation=\"relu\")\n",
    "#         self.dense2 = tf.keras.layers.Dense(128, activation=\"relu\")\n",
    "#         self.dense3 = tf.keras.layers.Dense(num_nodes)\n",
    "\n",
    "#         self.adj_shape = (num_timesteps, None, None)\n",
    "#         self.features_shape = (num_timesteps, None, num_features)\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         x, a = inputs[\"node_features\"], inputs[\"adj_matrix\"]\n",
    "#         a = tf.transpose(a, perm=[0, 2, 1])\n",
    "#         a = tf.linalg.matmul(a, tf.transpose(a, perm=[0, 2, 1]))\n",
    "#         x = self.conv1([x, a])\n",
    "#         x = self.conv2([x, a])\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dense2(x)\n",
    "#         x = self.dense3(x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "\n",
    "\n",
    "# # class GCN(tf.keras.Model):\n",
    "# #     def __init__(self, num_features, num_timesteps, num_nodes, dropout_rate=0.2):\n",
    "# #         super(GCN, self).__init__()\n",
    "\n",
    "# #         self.conv1 = GCNConv(256, activation=\"relu\")\n",
    "# #         self.conv2 = GCNConv(128, activation=\"relu\")\n",
    "# #         self.conv3 = GCNConv(64, activation=\"relu\")\n",
    "# #         self.flatten = tf.keras.layers.Flatten()\n",
    "# #         self.dense1 = tf.keras.layers.Dense(32, activation=\"relu\")\n",
    "# #         self.dense2 = tf.keras.layers.Dense(num_nodes*1, activation=\"linear\")\n",
    "\n",
    "# #         self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "# #         self.adj_shape = (num_timesteps, None, None)\n",
    "# #         self.features_shape = (num_timesteps, None, num_features)\n",
    "\n",
    "# #     def call(self, inputs):\n",
    "# #         x, a = inputs[\"node_features\"], inputs[\"adj_matrix\"]\n",
    "# #         a = tf.transpose(a, perm=[0, 2, 1])\n",
    "# #         a = tf.linalg.matmul(a, tf.transpose(a, perm=[0, 2, 1]))\n",
    "# #         x = self.conv1([x, a])\n",
    "# #         x = self.dropout(x)\n",
    "# #         x = self.conv2([x, a])\n",
    "# #         x = self.dropout(x)\n",
    "# #         x = self.conv3([x, a])\n",
    "# #         x = self.dropout(x)\n",
    "# #         x = self.flatten(x)\n",
    "# #         x = self.dense1(x)\n",
    "# #         x = self.dropout(x)\n",
    "# #         x = self.dense2(x)\n",
    "\n",
    "# #         return x\n",
    "\n",
    "\n",
    "\n",
    "# # import tensorflow as tf\n",
    "# # from spektral.layers import GCNConv\n",
    "# # from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "# # class GCN(tf.keras.Model):\n",
    "# #     def __init__(self, num_features, num_timesteps, num_nodes, dropout_rate=0.1):\n",
    "# #         super(GCN, self).__init__()\n",
    "\n",
    "# #         self.conv1 = GCNConv(256, activation=\"relu\")\n",
    "# #         self.conv2 = GCNConv(128, activation=\"relu\")\n",
    "# #         self.conv3 = GCNConv(64, activation=\"relu\")\n",
    "# #         self.flatten = tf.keras.layers.Flatten()\n",
    "# #         self.dense1 = tf.keras.layers.Dense(64, activation=\"relu\")\n",
    "# #         self.dense2 = tf.keras.layers.Dense(32, activation=\"relu\")\n",
    "# #         self.dense3 = tf.keras.layers.Dense(num_nodes*1)\n",
    "\n",
    "# #         self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "# #         self.adj_shape = (num_timesteps, None, None)\n",
    "# #         self.features_shape = (num_timesteps, None, num_features)\n",
    "\n",
    "# #     def call(self, inputs):\n",
    "# #         x, a = inputs[\"node_features\"], inputs[\"adj_matrix\"]\n",
    "# #         a = tf.transpose(a, perm=[0, 2, 1])\n",
    "# #         a = tf.linalg.matmul(a, tf.transpose(a, perm=[0, 2, 1]))\n",
    "# #         x = self.conv1([x, a])\n",
    "# #         x = self.dropout(x)\n",
    "# #         x = self.conv2([x, a])\n",
    "# #         x = self.dropout(x)\n",
    "# #         x = self.conv3([x, a])\n",
    "# #         x = self.dropout(x)\n",
    "# #         x = self.flatten(x)\n",
    "# #         x = self.dense1(x)\n",
    "# #         x = self.dropout(x)\n",
    "# #         x = self.dense2(x)\n",
    "# #         x = self.dropout(x)\n",
    "# #         x = self.dense3(x)\n",
    "# #         return x\n",
    "\n",
    "# model = GCN(num_features=num_features, num_timesteps=num_timesteps,num_nodes=num_nodes)\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss=\"mae\" )\n",
    "# history = model.fit(train_data, train_targets, epochs=100, batch_size=32, validation_data=(test_data, test_targets))\n",
    "\n",
    "# # Get training and validation loss from the history object\n",
    "# train_loss = history.history[\"loss\"]\n",
    "# val_loss = history.history[\"val_loss\"]\n",
    "\n",
    "# # Create a list of epoch numbers\n",
    "# epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# # Plot training and validation loss\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.lineplot(train_loss, label=\"Training Loss\")\n",
    "# sns.lineplot(val_loss, label=\"Validation Loss\")\n",
    "# plt.title(\"Training and Validation Loss\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mape(y_test, pred):\n",
    "#     y_test, pred = np.array(y_test), np.array(pred)\n",
    "#     mape = np.mean(np.abs((y_test - pred) / y_test))*100\n",
    "#     return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = model.predict(train_data)\n",
    "# train_targets = train_targets.reshape(2172,51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapeTensor = mape(predictions,train_targets)\n",
    "# mapeTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
